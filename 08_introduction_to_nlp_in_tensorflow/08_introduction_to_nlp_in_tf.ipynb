{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f528b0fa",
   "metadata": {},
   "source": [
    "### Introduction to NLP Fundamentals in TensorFlow\n",
    "\n",
    "    NLP has the goal of deriving information out of natural language (could be sequences text or speech)\n",
    "\n",
    "    Another common term for NLP problems is sequence to sequence problems (seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf06b446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce GTX 1650 (UUID: GPU-890aadbc-dc9a-cfdd-ce0d-dd3bdfa0ac28)\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e3543e7",
   "metadata": {},
   "outputs": [],
   "source": [
    " ## GET helper functions\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users/wjub/01workspace/TensorFlow Developer Certificate ZTM\")\n",
    "import winsound\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import helper_functions\n",
    "\n",
    "# Import series of helper functions for the notebook\n",
    "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys, calculate_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8b1fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22cff205",
   "metadata": {},
   "source": [
    "# Get a text dataset\n",
    "\n",
    "    The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labelled as disaste or not disasterrs)\n",
    "\n",
    "    See the original source here : https://www.kaggle.com/competitions/nlp-getting-started/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce775631",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_functions.download_file(\"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\",\"nlp_getting_started.zip\")\n",
    "helper_functions.unzip_data(\"nlp_getting_started.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfe9783",
   "metadata": {},
   "source": [
    "## Visualizing a text data \n",
    "\n",
    "        To visualize our text samples, we first have to read them in, one way to do so would be to use Python :\n",
    "\n",
    "        So another way to do this is to use pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87cef3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18773cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle training dataframe\n",
    "# frac : nb of % to shuffle 1=100%\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state = 42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4215322d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does the test dataframe look like ?\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "675a347d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many examples of each class ?\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "786529a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many total sample ?\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8e8a560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:1 (real diaster)\n",
      "Text:\n",
      "#world Fears over missing migrants in Med: Rescuers search for survivors after a boat carrying as many a... http://t.co/6DS67XAI5e #news\n",
      "\n",
      "---\n",
      "\n",
      "Target:0 (not real diaster)\n",
      "Text:\n",
      "So derailed_benchmark is cool for paths. i wonder if i can run it to find leaks in Jobs given to  resque  too?\n",
      "\n",
      "---\n",
      "\n",
      "Target:0 (not real diaster)\n",
      "Text:\n",
      "New Ladies Shoulder Tote Handbag Women Cross Body Bag Faux Leather Fashion Purse - Full reÛ_ http://t.co/y87Gi3BRlV http://t.co/1zbhVDCXzS\n",
      "\n",
      "---\n",
      "\n",
      "Target:1 (real diaster)\n",
      "Text:\n",
      "@Raishimi33 :) well I think that sounds like a fine plan where little derailment is possible so I applaud you :)\n",
      "\n",
      "---\n",
      "\n",
      "Target:1 (real diaster)\n",
      "Text:\n",
      "'Invading Iraq was a catastrophic mistake'.\n",
      "\n",
      "Diplomacy needs to replace constant threat of war by US and Israel:\n",
      "\n",
      "http://t.co/yqjpn3qUUX\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Let's visualize some random training examples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of  samples\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target:{target}\", \"(real diaster)\" if target > 0 else \"(not real diaster)\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c6363a",
   "metadata": {},
   "source": [
    "### Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27b99142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e25b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn dataframe values to dataframe columns\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                    train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                    test_size = 0.1, # use 10% of traianing data for validations\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea2f0e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 762, 6851, 762)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the lengths\n",
    "len(train_sentences), len(val_sentences), len(train_labels), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d55c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reshape data\n",
    "# train_sentences = train_sentences.reshape(-1, 1)\n",
    "# train_labels = train_labels.reshape(-1, 1)\n",
    "# val_labels = val_labels.reshape(-1, 1)\n",
    "# val_sentences = val_sentences.reshape(-1, 1)\n",
    "# train_sentences.shape, train_labels.shape, val_labels.shape, val_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79044a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the first 10 samples\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fc60f6",
   "metadata": {},
   "source": [
    "## Converting text into numbers\n",
    "\n",
    "    When dealing with a text problem, on of the first things you'll have to do before you can build a model is to convert your text to numbers.\n",
    "\n",
    "    There are a few ways to do this, namely:\n",
    "     * Tokenization - direct mapping of token (a token could be a word or a caracter) to number\n",
    "     * Embedding - create a matric of feature vector for each token (the size of the feature vector can be defined and this embedding can be learned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ecf611",
   "metadata": {},
   "source": [
    "# Text vectorization (tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c63cd922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "       'Imagine getting flattened by Kurt Zouma',\n",
       "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b395f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "# Use the default TextVectorization parameters\n",
    "text_vectorization = TextVectorization(max_tokens=50000, # how many words in the vocabulary(utomatically add <OOV>)\n",
    "                                       standardize=\"lower_and_strip_punctuation\",\n",
    "                                       split=\"whitespace\",\n",
    "                                       ngrams=None, # Create groups of n-words?\n",
    "                                       output_mode=\"int\", # How to map tokens to numbers\n",
    "                                       output_sequence_length=None, # how longdo you want your sequences to be?\n",
    "                                       pad_to_max_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c43fe036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@mogacola', '@zamtriossu', 'i', 'screamed', 'after', 'hitting', 'tweet']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1656007c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the average number of tokens (words) in the training tweets\n",
    "round(sum([len(i.split()) for i in train_sentences])) # nb of words\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences)) # average for 1 sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30b1d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup text vectorization variables\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 15 # max length our sequences will be \n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens = max_vocab_length,\n",
    "                                   output_mode = \"int\",\n",
    "                                   output_sequence_length= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aebb3a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer  to the training text \n",
    "# that convert our words data to numeric format \n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdb37a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentences and tokenize it \n",
    "sample_sentence = \"There's a flood in my street !\"\n",
    "text_vectorizer([sample_sentence])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e2d03de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origina text:\n",
      "Heat wave warning aa? Ayyo dei. Just when I plan to visit friends after a year.\n",
      "\n",
      " Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 288,  472,  338, 6288,    1,    1,   29,   45,    8,  241,    5,\n",
       "        1742,  819,   43,    3]], dtype=int64)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it \n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Origina text:\\n{random_sentence}\\\n",
    "\\n\\n Vectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "492ab2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in our training data\n",
    "top_5_words = words_in_vocab[:5] # get the most common words\n",
    "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"5 most common words: {top_5_words}\")\n",
    "print(f\"5 least common words: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ea47b",
   "metadata": {},
   "source": [
    "## Creating an Embedding using an Embedding Layer\n",
    "\n",
    "    To make our embedding, we re going to use TensorFlow's embedding layer : https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
    "    The parameters we xare most about for our embedding layer:\n",
    "    *`input_dim` = the size of our vocabulary\n",
    "    *`output_dim` = the size of the output embedding vector, for example, a value of 100 could mean each token gets represented by a vector 100 long\n",
    "    * `input_length` = length of the sequences being passed to the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e83597e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x1ab8554b580>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=128,\n",
    "                             embeddings_initializer=\"uniform\",\n",
    "                             input_length=max_length)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe840089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE http://t.co/qqsmshaJ3N\n",
      "\n",
      " Embedded version :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.01259222, -0.02260396, -0.0282679 , ...,  0.04498501,\n",
       "          0.02527041, -0.01866557],\n",
       "        [-0.01667808, -0.00251348, -0.02155714, ..., -0.01808948,\n",
       "          0.02658334, -0.01193937],\n",
       "        [-0.03097551,  0.00069269,  0.01390311, ...,  0.00333037,\n",
       "         -0.04288533,  0.02857199],\n",
       "        ...,\n",
       "        [ 0.00043489,  0.00190035,  0.03748127, ..., -0.01719388,\n",
       "         -0.01603042,  0.03695795],\n",
       "        [ 0.02399388, -0.02582198,  0.03950289, ..., -0.03432311,\n",
       "          0.04686573, -0.04798753],\n",
       "        [ 0.02399388, -0.02582198,  0.03950289, ..., -0.03432311,\n",
       "          0.04686573, -0.04798753]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from the training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "\\n\\n Embedded version :\")\n",
    "# Embed the random sentence (turn it into danse victors of fixed size)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "\n",
    "#sample_embed = tf.reshape(sample_embed, (1, 15, 128))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af574a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([-0.01259222, -0.02260396, -0.0282679 , -0.03223418,  0.04039583,\n",
       "         0.02806241,  0.04105767, -0.03088768, -0.0354462 , -0.02834523,\n",
       "         0.00583463,  0.03161821,  0.03396672, -0.00025386, -0.01558875,\n",
       "         0.02176858,  0.03669307,  0.04534841,  0.04414603, -0.04898053,\n",
       "         0.02281863, -0.00730277,  0.03802624,  0.04732194,  0.00593974,\n",
       "        -0.03590279,  0.0247716 , -0.03921125, -0.02366066,  0.02042564,\n",
       "        -0.00260689,  0.00564516, -0.01286004,  0.03689345, -0.00501659,\n",
       "         0.04730035,  0.0093969 ,  0.04789838, -0.01875985,  0.04328075,\n",
       "        -0.01055817, -0.02215543,  0.03457144, -0.03274769, -0.02053611,\n",
       "         0.0211804 ,  0.00405381,  0.00225909, -0.00845448, -0.01188415,\n",
       "        -0.01069843,  0.03529857, -0.04431583, -0.00214104,  0.01066195,\n",
       "         0.0233484 , -0.01993728, -0.0200797 , -0.03995167,  0.033649  ,\n",
       "         0.03745433,  0.01288137, -0.04712002, -0.04351516,  0.01703963,\n",
       "        -0.04779727,  0.02501675,  0.00895617,  0.01399635, -0.00807035,\n",
       "        -0.01017985,  0.00619977,  0.01198268, -0.03692238, -0.02211435,\n",
       "        -0.0261744 , -0.03204232,  0.01398462,  0.01939068,  0.03965094,\n",
       "         0.01704654, -0.00890989,  0.04359883, -0.00339646, -0.0195339 ,\n",
       "         0.04104425, -0.02416058, -0.03983838,  0.00536443,  0.04775322,\n",
       "         0.03030595,  0.04657232, -0.01574804, -0.0277601 , -0.0069776 ,\n",
       "        -0.04661583, -0.02432579, -0.02953426,  0.04691252, -0.02096751,\n",
       "        -0.04596043,  0.045646  , -0.0191458 ,  0.04085727, -0.025529  ,\n",
       "        -0.02337688,  0.04301329, -0.02896312, -0.04020004, -0.0344291 ,\n",
       "        -0.03473558, -0.00929068,  0.03838989,  0.02195222, -0.04572238,\n",
       "        -0.00591628,  0.03864414, -0.04003914, -0.00461155, -0.02034528,\n",
       "        -0.0198198 , -0.03526241,  0.01060473,  0.03062114,  0.02225551,\n",
       "         0.04498501,  0.02527041, -0.01866557], dtype=float32)>,\n",
       " TensorShape([128]),\n",
       " 'On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE http://t.co/qqsmshaJ3N')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out a single token's embedding\n",
    "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e78527",
   "metadata": {},
   "source": [
    "## Modelling a text dateset (running a series of experimente)\n",
    "\n",
    "    Now we ve a got way to turn our text sequences into numbers,\n",
    "    it's time to start building a series of modelling experiments.\n",
    "\n",
    "    We'll start with a baseline and moce on from there.\n",
    "\n",
    "* Model 0: Naive Bayes (baseline) with sklearn : https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "* Model 1: Feed-forward neural network (danse model)\n",
    "* Model 2 : LSTM model (RNN)\n",
    "* model 3 : GRU model (RNN)\n",
    "* model 4 : Bidirectional-LSTM model (RNN)\n",
    "* Model 5 : 1D Convolutional Neural Network (CNN)\n",
    "* Model 6 : TensorFlow Hub Pretrained Feature Extractor (using transfer learning for NLP)\n",
    "* Model 7 : Same as model 6 with 10% of training data\n",
    "\n",
    "How are we going to approch all of these ?\n",
    "\n",
    "Use the standard steps in modelling with tensorflow:\n",
    "\n",
    "* Create a model \n",
    "* Build a model\n",
    "* Fit a model\n",
    "* Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827f9c1",
   "metadata": {},
   "source": [
    "### Model 0 : Getting a baseline\n",
    "\n",
    "As with all machine learning modelling experiments, it's important to create a baseline model so you're got a benchmark for future experiments to build upon.\n",
    "\n",
    "To create our baseline, we'll use Sklearn's Multinomial Naive Bayers using the TF-IDF formula to convert our words to numbers\n",
    "\n",
    ">** note : ** it's common practice to use non-Deep Learning Algorithms as a baseline because of their speed and then later using Deep Learning to to see if you can imporove upon them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eda29d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline ([\n",
    "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
    "                    (\"clf\", MultinomialNB()) # model the text clf : juste classification\n",
    "])\n",
    "\n",
    "# Fit the pipleine to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8affb3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achives an accuracy of : 0.7926509186351706\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the baseline model\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achives an accuracy of : {baseline_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f286a72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:10]\n",
    "# for i in range(0,10,1):\n",
    "#     print(f\" {val_sentences[i]} \\n prediction : {baseline_preds[i]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5040405c",
   "metadata": {},
   "source": [
    "### Creating an evaluation function for our model experiments\n",
    "\n",
    "We could evaluate all of our model's predictions with different metrics every time, however this will be cumbersome and could easily be fixed with function\n",
    "\n",
    "Let's create one to compare our model's predictions with the truth labels using the following metrics:\n",
    "* Accuracy.\n",
    "* Precision.\n",
    "* Recall\n",
    "* F1-score\n",
    "\n",
    "For a deep overview of many different evaluation methods, see the sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74010e7d",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b59a21b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate : accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "# rajouter\n",
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "    \"\"\"\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    # Calculate model precision, recall and f1-score using \"weighted\" average\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\"accuracy\": model_accuracy,\n",
    "                    \"precision\": model_precision,\n",
    "                    \"recall\": model_recall,\n",
    "                    \"f1\": model_f1}\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7eaa603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9fb514",
   "metadata": {},
   "source": [
    "# Model 1: A simple dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02459538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensorboard callback (need to create a new one for each model)\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Create a directory to save TensorBoard logs\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f468f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0264dbea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a96f1e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with the Functional API\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional string\n",
    "x = text_vectorizer(inputs)# turn the input text into numbers\n",
    "x = embedding(x) # transform the input numbers in embedding\n",
    "x = layers.GlobalAveragePooling1D()(x) # Condense the feature vector for each token to on vector\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # Create the output layer, want binary outputs\n",
    "model_1 = tf.keras.Model(inputs,outputs, name=\"Model_1_dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "623d114e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a42935a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ac54d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96dc79b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_dense/20230116-222018\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 4s 6ms/step - loss: 0.6115 - accuracy: 0.6989 - val_loss: 0.5357 - val_accuracy: 0.7572\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.4414 - accuracy: 0.8173 - val_loss: 0.4702 - val_accuracy: 0.7848\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.3464 - accuracy: 0.8599 - val_loss: 0.4568 - val_accuracy: 0.7887\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.2837 - accuracy: 0.8936 - val_loss: 0.4651 - val_accuracy: 0.7887\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.2369 - accuracy: 0.9118 - val_loss: 0.4827 - val_accuracy: 0.7835\n"
     ]
    }
   ],
   "source": [
    "history_model_1 = model_1.fit(x=train_sentences,\n",
    "                              y=train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences,val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                        experiment_name=\"model_1_dense\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69867b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.482700377702713, 0.7834645509719849]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dec3e5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762, 1), array([0.40546677], dtype=float32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs.shape, model_1_pred_probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "298c0583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40546677],\n",
       "       [0.8031199 ],\n",
       "       [0.9978848 ],\n",
       "       [0.13206421],\n",
       "       [0.11119317],\n",
       "       [0.9426388 ],\n",
       "       [0.9129343 ],\n",
       "       [0.9939521 ],\n",
       "       [0.9678228 ],\n",
       "       [0.2901585 ]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at a single prediction\n",
    "model_1_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27159324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(762, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a10ee1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model prediction probabilities to label format\n",
    "\n",
    "model_1_pred_probs = tf.squeeze(tf.round(model_1_pred_probs))\n",
    "model_1_pred_probs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "619cc4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.34645669291339,\n",
       " 'precision': 0.7880043492637875,\n",
       " 'recall': 0.7834645669291339,\n",
       " 'f1': 0.7804929895574078}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate our model_1 results\n",
    "model_1_results = calculate_results(y_true=val_labels,\n",
    "                                   y_pred=model_1_pred_probs)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f69fa1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ab6ee6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare witch best between our models\n",
    "import numpy as np\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values())) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581df9fd",
   "metadata": {},
   "source": [
    "## Visualizing learned embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2365df42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vocabulary from the text vectorization layer\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "510d1ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_vocab_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1be59242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 1 summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07871965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "# Get the weight matrix of embedding layer\n",
    "# (thse are the numerical representations of each token in our training data, which have been learned for -5 epochs)\n",
    "embed_weights = model_1.get_layer(\"embedding\").get_weights()\n",
    "print(embed_weights[0].shape) # same size as vocab size and embedding_dim (output_dim of our embedding layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae02c0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.03820484, -0.01344948,  0.02937469, ..., -0.04787105,\n",
       "          0.04021944, -0.06293101],\n",
       "        [ 0.00721968,  0.00771107,  0.03239628, ..., -0.02388553,\n",
       "         -0.01896044,  0.02937855],\n",
       "        [ 0.00973042,  0.05472668,  0.00695324, ..., -0.02302973,\n",
       "          0.01827305,  0.01544901],\n",
       "        ...,\n",
       "        [ 0.02152051, -0.03912783,  0.0219495 , ..., -0.03770596,\n",
       "         -0.01462867, -0.02694877],\n",
       "        [-0.00443885,  0.07291612,  0.00105182, ..., -0.00767418,\n",
       "         -0.02795472,  0.00116968],\n",
       "        [ 0.0764626 ,  0.03179592, -0.05615811, ..., -0.06207443,\n",
       "         -0.0646542 , -0.05228703]], dtype=float32)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb017c9",
   "metadata": {},
   "source": [
    "Now we've got the embedding matric our model has learned to represent our tokens, let's see how we can visualize it.\n",
    "\n",
    "To do so, TensorFlow has a handly tool called projector: https://projector.tensorflow.org/\n",
    "\n",
    "And TensorFlow also has an incredible guide on word embeddings themselves\n",
    "https://www.tensorflow.org/text/guide/word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d9af286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create embedding files (we got this from TensorFlow's word embedding documentation)\n",
    "# import io\n",
    "# out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "# out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "# for index, word in enumerate(words_in_vocab):\n",
    "#   if index == 0:\n",
    "#     continue  # skip 0, it's padding.\n",
    "#   vec = embed_weights[0][index]\n",
    "#   out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "#   out_m.write(word + \"\\n\")\n",
    "# out_v.close()\n",
    "# out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72e77185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#   from google.colab import files\n",
    "#   files.download('vectors.tsv')\n",
    "#   files.download('metadata.tsv')\n",
    "# except Exception:\n",
    "#   pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2091a5",
   "metadata": {},
   "source": [
    "Downloading the files above can visualize them usign http://projector.tensorflow.org/ and clicking the \"load\" button on the left hand\n",
    "*Ressources : if you'd like to know more about embedding, I'd encourage you to check out :\n",
    "- Jay Alammer's vusualized word2vec post : https://jalammar.github.io/illustrated-word2vec/\n",
    "- TensorFlow's Word Embeddings guide: https://www.tensorflow.org/tutorials/text/word_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b722294",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks (RNN's)\n",
    "\n",
    "RNN's are useful for sequence data.\n",
    "\n",
    "The premise of a recurrent neural network is to use the representation of a previous input to aid the representation of a later\n",
    "* Ressources :> \n",
    "If you want an overview of the internale of a recurrent neural network, see the following : \n",
    "    - MIT's sequence modelling lecture https://www.youtube.com/watch?v=QvkQ1B3FBqA\n",
    "    - Chris Olah's intro to LSTMs : https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "    - Andrej Karphathy's the unreasonable effectiveness of recurrent neural network : http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "    - https://www.youtube.com/watch?v=QvkQ1B3FBqA&t=166s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff9cdd7",
   "metadata": {},
   "source": [
    "### Model 2 : LSTM \n",
    "LSTM = long short term memory (one of the most popular LSTM cells)\n",
    "\n",
    "Our structure of an RNN Typically looks like this:\n",
    "\n",
    "```\n",
    "Input (text) -> Tokenize -> Embedding -> Layers (RNNs/dense) -> Output (label probability)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "645c0589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Create an LSTM model\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "# print(x.shape)\n",
    "# x = layers.LSTM(units=64, return_sequences=True)(x) # when you're stacking RNN cells together, you need to  returns sequences=True\n",
    "# print(x.shape)\n",
    "x = layers.LSTM(64, activation=\"relu\")(x)\n",
    "# print(x.shape)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "# print(x.shape)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ba1f09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the summary \n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "73ca3542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5407aaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_2_LSTM/20230116-222130\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 12s 49ms/step - loss: 0.2545 - accuracy: 0.9053 - val_loss: 0.6648 - val_accuracy: 0.7795\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 11s 49ms/step - loss: 0.1705 - accuracy: 0.9356 - val_loss: 0.8671 - val_accuracy: 0.7756\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 10s 48ms/step - loss: 0.1333 - accuracy: 0.9473 - val_loss: 0.9047 - val_accuracy: 0.7743\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 10s 48ms/step - loss: 0.1083 - accuracy: 0.9575 - val_loss: 0.8564 - val_accuracy: 0.7717\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 10s 48ms/step - loss: 0.0892 - accuracy: 0.9670 - val_loss: 1.1356 - val_accuracy: 0.7677\n"
     ]
    }
   ],
   "source": [
    "# Fit the model \n",
    "history_model2 = model_2.fit(train_sentences,\n",
    "                            train_labels,\n",
    "                            epochs=5,\n",
    "                            validation_data=(val_sentences,val_labels),\n",
    "                            callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                   experiment_name=\"model_2_LSTM\")]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "74d422e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.9303145e-02],\n",
       "       [8.9158654e-01],\n",
       "       [1.0000000e+00],\n",
       "       [4.1239511e-02],\n",
       "       [1.1321775e-04],\n",
       "       [1.0000000e+00],\n",
       "       [7.7143604e-01],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [6.4978713e-01]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make prediction with LSTM model\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4472f23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model 2 pred probs to labels\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs)) # enlever les dimension en plus\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2549d5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.77165354330708,\n",
       " 'precision': 0.7679905783589133,\n",
       " 'recall': 0.7677165354330708,\n",
       " 'f1': 0.7663871505080737}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 2 results\n",
    "model_2_results = calculate_results(val_labels, model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "210c59df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6126e4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(model_1_results.values())) > np.array(list(model_2_results.values()))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c052c",
   "metadata": {},
   "source": [
    "### Model 3 : GRU\n",
    "\n",
    "Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
    "\n",
    "The GRU cell has similar features to an LSTM cell but has less parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1c849c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an RNN GRU\n",
    "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.GRU(3)(x)\n",
    "# x = tf.keras.layers.GRU(units=64, return_sequences=True)(x) \n",
    "# x = tf.keras.layers.LSTM(42, return_sequences=True)(x)\n",
    "# x = tf.keras.layers.GRU(units=92, return_sequences=True)(x)\n",
    "\n",
    "# # Apply global average pooling\n",
    "# x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "# x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f14dcfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Version 2\n",
    "# # Build an RNN GRU\n",
    "# inputs = tf.keras.layers.Input(shape=(1), dtype=tf.string)\n",
    "# x = text_vectorizer(inputs)\n",
    "# x = embedding(x)\n",
    "# # x = tf.keras.layers.GRU(64)(x)\n",
    "# x = tf.keras.layers.GRU(units=64, return_sequences=True)(x) \n",
    "# x = tf.keras.layers.LSTM(42, return_sequences=True)(x)\n",
    "# x = tf.keras.layers.GRU(units=92, return_sequences=True)(x)\n",
    "\n",
    "# # Apply global average pooling\n",
    "# x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "# x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "# outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "# model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523aa55f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "378874d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 3)                 1197      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,281,201\n",
      "Trainable params: 1,281,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "401f412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model_3.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b38faef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_3_GRU/20230116-222224\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 11ms/step - loss: 0.5226 - accuracy: 0.7714 - val_loss: 0.4991 - val_accuracy: 0.7835\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.2452 - accuracy: 0.9340 - val_loss: 0.4797 - val_accuracy: 0.7940\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1511 - accuracy: 0.9628 - val_loss: 0.5379 - val_accuracy: 0.7795\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1146 - accuracy: 0.9718 - val_loss: 0.5647 - val_accuracy: 0.7822\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0959 - accuracy: 0.9749 - val_loss: 0.6120 - val_accuracy: 0.7782\n"
     ]
    }
   ],
   "source": [
    "model_3_history = model_3.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences,val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                        experiment_name=\"model_3_GRU\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0525da1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make som prediction with our GRU model\n",
    "model_3_pred_probs = model_3.predict(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "59c4eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dd6ecf73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.82152230971128,\n",
       " 'precision': 0.7804499491198106,\n",
       " 'recall': 0.7782152230971129,\n",
       " 'f1': 0.7760126933653841}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_results = calculate_results(val_labels, model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3fe67d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing model 1 with model 2\n",
    "np.array(list(model_1_results.values())) > np.array(list(model_3_results.values()))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec2bf59",
   "metadata": {},
   "source": [
    "# Mode 4 :  Bidirectional RNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3445cc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, activation=\"relu\"))(x)\n",
    "# x = tf.keras.layers.AveragePooling1D()(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional_layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "83c6bff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_Bidirectional_layer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,378,945\n",
      "Trainable params: 1,378,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c614561d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "model_4_predict_prob = tf.squeeze(model_4.predict(val_sentences))\n",
    "model_4_preds = tf.round(model_4_predict_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b25eb8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 28.21522309711286,\n",
       " 'precision': 0.28573041411174227,\n",
       " 'recall': 0.2821522309711286,\n",
       " 'f1': 0.2808821854759865}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_results = calculate_results(val_labels, model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a0ef3d",
   "metadata": {},
   "source": [
    "# Model 4 : Bidirectional RNN\n",
    "\n",
    "Normal RNN's go from left to right (just like you'd read an English sentence), however, bidirectional RNN goes from right to left as well as left to right.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "36dd2e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 128)\n"
     ]
    }
   ],
   "source": [
    "# Build a bidirectional RNN in TensorFlow \n",
    "# create the model\n",
    "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64))(x)\n",
    "print(x.shape) # nb_units * 2 comme c'est bidirectional\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional_layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d4cf9997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_Bidirectional_layer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 15, 128)          98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 128)              74496     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,453,441\n",
      "Trainable params: 1,453,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " # Get a summary \n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b777645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_4.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "84114288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/Bidirectionalmod/20230116-222239\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 10s 23ms/step - loss: 0.1210 - accuracy: 0.9612 - val_loss: 0.7434 - val_accuracy: 0.7730\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.0789 - accuracy: 0.9704 - val_loss: 0.8741 - val_accuracy: 0.7835\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0662 - accuracy: 0.9736 - val_loss: 0.9137 - val_accuracy: 0.7717\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0594 - accuracy: 0.9750 - val_loss: 0.8923 - val_accuracy: 0.7782\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 16ms/step - loss: 0.0514 - accuracy: 0.9799 - val_loss: 1.2683 - val_accuracy: 0.7717\n"
     ]
    }
   ],
   "source": [
    "history_model_4 = model_4.fit(train_sentences,\n",
    "                             train_labels,\n",
    "                             epochs=5,\n",
    "                             validation_data=(val_sentences, val_labels),\n",
    "                             callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                    experiment_name=\"Bidirectionalmod\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7808cffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make prediction with our bidirectional model\n",
    "model_4_predict_prob = tf.squeeze(model_4.predict(val_sentences))\n",
    "# Convert pred probs to labels \n",
    "model_4_preds = tf.round(model_4_predict_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b3239c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.16535433070865,\n",
       " 'precision': 0.7722289521502119,\n",
       " 'recall': 0.7716535433070866,\n",
       " 'f1': 0.7701831305177762}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert pred probs to labels \n",
    "model_4_results = calculate_results(val_labels, model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77f2dd4",
   "metadata": {},
   "source": [
    "## Convolution Neural Networks for Text (and other types of sequences)\n",
    "\n",
    "We've used CNNs for images but images are typically 2D (geight x width)... however, our text data is 1D.\n",
    "\n",
    "Previously we've Conv2D for our image data but now we're going to use Conv1D.\n",
    "\n",
    "The typical structure of a Conv1D model for sequences (in our case, text):\n",
    "\n",
    "Inputs (text) -> Tokenization -> Embedding -> Layer(s) (typicallyConv1D + Pooling layer) -> Pooling -> Outputs (class probabilities) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e151725",
   "metadata": {},
   "source": [
    "## Model 5 : Conv1D\n",
    "\n",
    "For different explanations of parameters see:\n",
    "* https://poloclub.github.io/cnn-explainer/\n",
    "* Difference between \"same\" and \"valid\" padding:https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t#:~:text=To%20sum%20up%2C%20'valid',same'%20padding%20means%20using%20padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "af1d6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_test = embedding(text_vectorizer([\"c est test de phrase\"]))\n",
    "# conv_1d = tf.keras.layers.Conv1D(filters=32,\n",
    "#                                  kernel_size=5 , \n",
    "#                                  activation=\"relu\",\n",
    "#                                  padding=\"valid\")\n",
    "# conv_1d_output = conv_1d(embedding_test) # pass test embedding through conv1d layer\n",
    "# max_pool = tf.keras.layers.GlobalAvgPool1D()\n",
    "# max_pool_output = max_pool(conv_1d_output) # equivalent to \"get the most important feature\" or \"get the feature with the highest value\"\n",
    "\n",
    "# embedding_test.shape, conv_1d_output.shape, max_pool_output.shape\n",
    "# # embedding_test\n",
    "# # conv_1d_output\n",
    "# # max_pool_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f5e1afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out our embedding layer, Conv1D layer and max pooling\n",
    "inputs = tf.keras.layers.Input(shape=(1), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.Conv1D(filters=64,\n",
    "                           kernel_size=5 , \n",
    "                           activation=\"relu\",\n",
    "                           strides=1,\n",
    "                           padding=\"valid\")(x)\n",
    "x = tf.keras.layers.GlobalAvgPool1D()(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a29bf3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_Conv1d\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 11, 64)            41024     \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,321,089\n",
      "Trainable params: 1,321,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "# Get a summary of our Conv1D model\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "de9c55d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_5_Conv1d/20230116-222305\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 8ms/step - loss: 0.1685 - accuracy: 0.9350 - val_loss: 0.7964 - val_accuracy: 0.7612\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.1007 - accuracy: 0.9577 - val_loss: 0.8963 - val_accuracy: 0.7585\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.0807 - accuracy: 0.9680 - val_loss: 1.0285 - val_accuracy: 0.7507\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.0682 - accuracy: 0.9708 - val_loss: 1.1343 - val_accuracy: 0.7598\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.0606 - accuracy: 0.9731 - val_loss: 1.2970 - val_accuracy: 0.7612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aca8043dc0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.fit(train_sentences,\n",
    "            train_labels,\n",
    "            epochs=5,\n",
    "            validation_data=(val_sentences, val_labels),\n",
    "            callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                 experiment_name=\"model_5_Conv1d\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4aa6f041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_pred_probs\n",
    "# convert model_5_pred_probs to labels 0 or 1\n",
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "# model_5_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "47be0631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.11548556430446,\n",
       " 'precision': 0.7622953452640989,\n",
       " 'recall': 0.7611548556430446,\n",
       " 'f1': 0.7591215732608759}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_results = calculate_results(val_labels, model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0947a399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check witch the best \n",
    "np.array(list(model_5_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e27470",
   "metadata": {},
   "source": [
    "# Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
    "\n",
    "Now we've built a few of our own models, let's try and use transfer learning for NLP, specifically using TensorFlow Hub's Universal Sentence Encoder : https://tfhub.dev/google/universal-sentence-encoder/4\n",
    "\n",
    "https://colab.research.google.com/drive/1tjnmiNUxxR090bVcze1jD_J4svhPPy_W#scrollTo=XC37Wot1Fw74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "08b1374e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.62729658792651,\n",
       " 'precision': 0.8162262387656088,\n",
       " 'recall': 0.8162729658792651,\n",
       " 'f1': 0.8157886543602123}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_results = {'accuracy': 81.62729658792651,\n",
    "                   'precision': 0.8162262387656088,\n",
    "                   'recall': 0.8162729658792651,\n",
    "                   'f1': 0.8157886543602123}\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88eeb28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24ccf076",
   "metadata": {},
   "source": [
    "# Model 7: TF Hub Pretrained USE but with 10% of training data \n",
    "\n",
    "Transfer learning really helps when you don't have a large dataset.\n",
    "\n",
    "To see how our modeel performs on a smaller dataset, let's replicate `model _6` except we'll train it on 10% of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c1cf6f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.55905511811024,\n",
       " 'precision': 0.7765218346613636,\n",
       " 'recall': 0.7755905511811023,\n",
       " 'f1': 0.7739772681043204}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_results = {'accuracy': 77.55905511811024,\n",
    "                   'precision': 0.7765218346613636,\n",
    "                   'recall': 0.7755905511811023,\n",
    "                   'f1': 0.7739772681043204}\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472a7e8e",
   "metadata": {},
   "source": [
    "    **Note : ** Be *very* careful when creating training/val/test split that you d'ont leak data across the datasets, otherwise your model evaluation metrics will be wrong. If something looks too good to be true (a model trained on 10% of data outperforming the same model trained on 100% of data) trust your gut and go back through to find where the error may lie.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d68f9fd",
   "metadata": {},
   "source": [
    "## Comparing the performance of each of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ab5ab391",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
    "                                \"1_simple_dense\": model_1_results,\n",
    "                                \"2_lstm\":model_2_results,\n",
    "                                \"3_gru\":model_3_results,\n",
    "                                \"4_bidirectional\": model_4_results,\n",
    "                                \"5_conv1d\": model_5_results,\n",
    "                                \"6_tf_hub_use_encoder\": model_6_results,\n",
    "                                \"7_tf_hub_use_encoder_10_percent\": model_7_results})\n",
    "all_model_results = all_model_results.transpose()\n",
    "# Reduce the accuracy to the same scale as other metrics\n",
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1f916c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_simple_dense</th>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.788004</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.780493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_lstm</th>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.767991</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.766387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_gru</th>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.780450</td>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.776013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_bidirectional</th>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.772229</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.770183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_conv1d</th>\n",
       "      <td>0.761155</td>\n",
       "      <td>0.762295</td>\n",
       "      <td>0.761155</td>\n",
       "      <td>0.759122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_tf_hub_use_encoder</th>\n",
       "      <td>0.816273</td>\n",
       "      <td>0.816226</td>\n",
       "      <td>0.816273</td>\n",
       "      <td>0.815789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
       "      <td>0.775591</td>\n",
       "      <td>0.776522</td>\n",
       "      <td>0.775591</td>\n",
       "      <td>0.773977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 accuracy  precision    recall        f1\n",
       "baseline                         0.792651   0.811139  0.792651  0.786219\n",
       "1_simple_dense                   0.783465   0.788004  0.783465  0.780493\n",
       "2_lstm                           0.767717   0.767991  0.767717  0.766387\n",
       "3_gru                            0.778215   0.780450  0.778215  0.776013\n",
       "4_bidirectional                  0.771654   0.772229  0.771654  0.770183\n",
       "5_conv1d                         0.761155   0.762295  0.761155  0.759122\n",
       "6_tf_hub_use_encoder             0.816273   0.816226  0.816273  0.815789\n",
       "7_tf_hub_use_encoder_10_percent  0.775591   0.776522  0.775591  0.773977"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f99ba25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all of the model results\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10,7)).legend(bbox_to_anchor=(1.0,1.0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5d8844b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort model results by f1-score\n",
    "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632f0438",
   "metadata": {},
   "source": [
    "### Uploading our modeel training logs to TensorBoard.dev\n",
    "we can further inspect our model's performance using tensorboard.dev : https://tensorboard.dev/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5f860b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard dev upload --logdir ./model_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "99ac32c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorboard==2.11\n",
    "#!pip uninstall flatbuffers\n",
    "#!pip uninstall -y tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "74342cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard dev upload --logdir ./model_logs/ \\\n",
    "#  --name \"7 models experiment\" \\\n",
    "#  --description \"Training results from http://localhost:8888/notebooks/01workspace/TensorFlow%20Developer%20Certificate%20ZTM/partie_2/TensorFlow_Developer_Certificate_ZTM/08_introduction_to_nlp_in_tensorflow/08_introduction_to_nlp_in_tf.ipynb\" \\\n",
    "#  --one_shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b2dfd2",
   "metadata": {},
   "source": [
    "### Load model already saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c28375f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = tf.keras.models.load_model(\"save_models/model_6.H5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3266283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = tf.keras.models.load_model(\"save_models/model_4.H5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "797ce995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7894bb17",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nJIT compilation failed.\n\t [[{{node EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup/mod}}]] [Op:__inference_test_function_86051]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [109]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_6\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_sentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnknownError\u001b[0m: Graph execution error:\n\nJIT compilation failed.\n\t [[{{node EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup/mod}}]] [Op:__inference_test_function_86051]"
     ]
    }
   ],
   "source": [
    "model_4.evaluate(val_sentences,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d9138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
