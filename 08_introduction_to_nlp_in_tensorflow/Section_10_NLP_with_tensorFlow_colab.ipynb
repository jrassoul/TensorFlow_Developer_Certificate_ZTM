{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmdTOX7bGUZ6"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwHS2EXaPHRD"
      },
      "source": [
        "## Nouvelle section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NMYi6mKPmNW"
      },
      "outputs": [],
      "source": [
        " ## GET helper functions\n",
        "import sys\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import helper_functions\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "SAVE_DIR = \"model_logs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubTcP39GU2Dl"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate : accuracy, precision, recall, f1-score<\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "# rajouter\n",
        "def calculate_results(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "    \"\"\"\n",
        "    # Calculate model accuracy\n",
        "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "    # Calculate model precision, recall and f1-score using \"weighted\" average\n",
        "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "    model_results = {\"accuracy\": model_accuracy,\n",
        "                    \"precision\": model_precision,\n",
        "                    \"recall\": model_recall,\n",
        "                    \"f1\": model_f1}\n",
        "    return model_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oh8236JPPuZR"
      },
      "outputs": [],
      "source": [
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45hFBOqWPuWH"
      },
      "outputs": [],
      "source": [
        "helper_functions.download_file(\"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\",\"nlp_getting_started.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISxpQAriPuTA"
      },
      "outputs": [],
      "source": [
        "helper_functions.unzip_data(\"nlp_getting_started.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yyacDpsyPuQS",
        "outputId": "af2d750f-38ea-4c89-aa3b-0e7dda66a716"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-04950509-5257-46e8-a25f-1736918ed3e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04950509-5257-46e8-a25f-1736918ed3e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-04950509-5257-46e8-a25f-1736918ed3e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-04950509-5257-46e8-a25f-1736918ed3e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()\n",
        "# train_df[\"text\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ky2J9mI8PuNm",
        "outputId": "d275717b-530a-4dad-ba84-aef624cf6307"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-15e76795-d7b0-415a-a9ce-07c28782f8af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15e76795-d7b0-415a-a9ce-07c28782f8af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15e76795-d7b0-415a-a9ce-07c28782f8af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15e76795-d7b0-415a-a9ce-07c28782f8af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Shuffle training dataframe\n",
        "# frac : nb of % to shuffle 1=100%\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state = 42)\n",
        "test_df_shuffled = train_df.sample(frac=1, random_state = 42)\n",
        "train_df_shuffled.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dc_GQDHl1hJ-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j6jYrASemRv",
        "outputId": "48cb390d-d4a3-4ca7-8d4f-34d5bf60d8bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target:1 (real diaster)\n",
            "Text:\n",
            "@Miss_HoMaStToPa cause were on fire we are on fire were on fire now.. Yeah were on fire we are on fire were on fire nowwwwww\n",
            "\n",
            "---\n",
            "\n",
            "Target:1 (real diaster)\n",
            "Text:\n",
            "Railways caught unawares by MP tragedy; Accident spot never marked as 'vulnerable' - Times ofÛ_ http://t.co/cEdCUgEuWs #News\n",
            "\n",
            "---\n",
            "\n",
            "Target:0 (not real diaster)\n",
            "Text:\n",
            "Advice from Noah: Dont go running in a thunderstorm\n",
            "\n",
            "---\n",
            "\n",
            "Target:1 (real diaster)\n",
            "Text:\n",
            "UNR issues Severe Thunderstorm Warning [wind: 60 MPH hail: 0.75 IN] for Weston [WY] and Custer Fall River Lawrence Meade Pennington [SÛ_\n",
            "\n",
            "---\n",
            "\n",
            "Target:1 (real diaster)\n",
            "Text:\n",
            "Virgin galactic crash: early unlocking of brakes triggered structural failure http://t.co/Kp1hDchfNZ\n",
            "\n",
            "---\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(6851, 762, 6851, 762)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# ### Introduction to NLP Fundamentals in TensorFlow\n",
        "# \n",
        "#     NLP has the goal of deriving information out of natural language (could be sequences text or speech)\n",
        "# \n",
        "#     Another common term for NLP problems is sequence to sequence problems (seq2seq)\n",
        "\n",
        "\n",
        "# Check for GPU\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Get a text dataset\n",
        "# \n",
        "#     The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labelled as disaste or not disasterrs)\n",
        "# \n",
        "#     See the original source here : https://www.kaggle.com/competitions/nlp-getting-started/data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# What does the test dataframe look like ?\n",
        "test_df.head()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# How many examples of each class ?\n",
        "train_df.target.value_counts()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# How many total sample ?\n",
        "len(train_df), len(test_df)\n",
        "\n",
        "\n",
        "\n",
        "#  Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of  samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "    _, text, target = row\n",
        "    print(f\"Target:{target}\", \"(real diaster)\" if target > 0 else \"(not real diaster)\")\n",
        "    print(f\"Text:\\n{text}\\n\")\n",
        "    print(\"---\\n\")\n",
        "\n",
        "\n",
        "# ### Split data into training and validation sets\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "# turn dataframe values to dataframe columns\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                    train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                    test_size = 0.1, # use 10% of traianing data for validations\n",
        "                                                    random_state = 42)\n",
        "\n",
        "\n",
        "# Check the lengths\n",
        "len(train_sentences), len(val_sentences), len(train_labels), len(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA-yeGjiuTJV",
        "outputId": "ed3803bf-be70-4201-c64a-e1b65a093368"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Origina text:\n",
            "Governor allows parole for California school bus hijacker | Fresno Linked Local Network http://t.co/Sww0QsMxVM http://t.co/bcdP4gKokA\n",
            "\n",
            " Vectorized version:\n",
            "Number of words in vocab: 10000\n",
            "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n",
            "Original text:\n",
            "Sinkhole swallows Brooklyn intersection ÛÒ video http://t.co/1yBE5mgZL4 http://t.co/7Zog3DpdU9\n",
            "\n",
            " Embedded version :\n",
            "Our baseline model achives an accuracy of : 0.7926509186351706\n",
            "Model: \"Model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Saving TensorBoard log files to: model_logs/model_1_dense/20230125-202726\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 3s 5ms/step - loss: 0.6098 - accuracy: 0.6989 - val_loss: 0.5360 - val_accuracy: 0.7520\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.4408 - accuracy: 0.8199 - val_loss: 0.4720 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.3465 - accuracy: 0.8608 - val_loss: 0.4579 - val_accuracy: 0.7913\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2839 - accuracy: 0.8920 - val_loss: 0.4611 - val_accuracy: 0.7822\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2370 - accuracy: 0.9118 - val_loss: 0.4804 - val_accuracy: 0.7861\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7861\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "Model: \"Model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 128)\n",
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20230125-202734\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 9s 34ms/step - loss: 0.2445 - accuracy: 0.9133 - val_loss: 0.7292 - val_accuracy: 0.7861\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.1670 - accuracy: 0.9342 - val_loss: 0.6107 - val_accuracy: 0.7900\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 7s 31ms/step - loss: 0.1329 - accuracy: 0.9477 - val_loss: 0.8245 - val_accuracy: 0.7808\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.1091 - accuracy: 0.9566 - val_loss: 0.9297 - val_accuracy: 0.7598\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 7s 32ms/step - loss: 0.0900 - accuracy: 0.9648 - val_loss: 1.8057 - val_accuracy: 0.7690\n",
            "24/24 [==============================] - 0s 4ms/step\n",
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 3)                 1197      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,281,201\n",
            "Trainable params: 1,281,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20230125-202817\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 8ms/step - loss: 0.5432 - accuracy: 0.7402 - val_loss: 0.4988 - val_accuracy: 0.7730\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.2783 - accuracy: 0.9120 - val_loss: 0.4801 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1776 - accuracy: 0.9507 - val_loss: 0.5167 - val_accuracy: 0.7703\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1272 - accuracy: 0.9642 - val_loss: 0.5726 - val_accuracy: 0.7756\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.1006 - accuracy: 0.9714 - val_loss: 0.6031 - val_accuracy: 0.7756\n",
            "24/24 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4_Bidirectional_layer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "24/24 [==============================] - 1s 13ms/step\n",
            "(None, 128)\n",
            "Model: \"model_4_Bidirectional_layer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 15, 128)          98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 128)              74496     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,453,441\n",
            "Trainable params: 1,453,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Saving TensorBoard log files to: model_logs/Bidirectionalmod/20230125-202833\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 11s 17ms/step - loss: 0.1313 - accuracy: 0.9543 - val_loss: 0.7478 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.0790 - accuracy: 0.9715 - val_loss: 0.9901 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.0671 - accuracy: 0.9734 - val_loss: 0.8636 - val_accuracy: 0.7730\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0591 - accuracy: 0.9771 - val_loss: 0.8860 - val_accuracy: 0.7664\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 12ms/step - loss: 0.0511 - accuracy: 0.9777 - val_loss: 1.2993 - val_accuracy: 0.7756\n",
            "24/24 [==============================] - 1s 5ms/step\n",
            "Model: \"model_5_Conv1d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 64)               0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Saving TensorBoard log files to: model_logs/model_5_Conv1d/20230125-202856\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 6ms/step - loss: 0.1758 - accuracy: 0.9349 - val_loss: 0.7603 - val_accuracy: 0.7677\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.1032 - accuracy: 0.9594 - val_loss: 0.8954 - val_accuracy: 0.7677\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0825 - accuracy: 0.9669 - val_loss: 0.9795 - val_accuracy: 0.7625\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0712 - accuracy: 0.9698 - val_loss: 1.1503 - val_accuracy: 0.7651\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0643 - accuracy: 0.9726 - val_loss: 1.1952 - val_accuracy: 0.7677\n",
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Reshape data\n",
        "# train_sentences = train_sentences.reshape(-1, 1)\n",
        "# train_labels = train_labels.reshape(-1, 1)\n",
        "# val_labels = val_labels.reshape(-1, 1)\n",
        "# val_sentences = val_sentences.reshape(-1, 1)\n",
        "# train_sentences.shape, train_labels.shape, val_labels.shape, val_sentences.shape\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]\n",
        "\n",
        "\n",
        "# ## Converting text into numbers\n",
        "# \n",
        "#     When dealing with a text problem, on of the first things you'll have to do before you can build a model is to convert your text to numbers.\n",
        "# \n",
        "#     There are a few ways to do this, namely:\n",
        "#      * Tokenization - direct mapping of token (a token could be a word or a caracter) to number\n",
        "#      * Embedding - create a matric of feature vector for each token (the size of the feature vector can be defined and this embedding can be learned)\n",
        "\n",
        "# # Text vectorization (tokenization)\n",
        "\n",
        "\n",
        "\n",
        "train_sentences[:5]\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization parameters\n",
        "text_vectorization = TextVectorization(max_tokens=50000, # how many words in the vocabulary(utomatically add <OOV>)\n",
        "                                       standardize=\"lower_and_strip_punctuation\",\n",
        "                                       split=\"whitespace\",\n",
        "                                       ngrams=None, # Create groups of n-words?\n",
        "                                       output_mode=\"int\", # How to map tokens to numbers\n",
        "                                       output_sequence_length=None, # how longdo you want your sequences to be?\n",
        "                                       pad_to_max_tokens=True)\n",
        "\n",
        "\n",
        "\n",
        "train_sentences[0].split()\n",
        "\n",
        "\n",
        "\n",
        "# Find the average number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])) # nb of words\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences)) # average for 1 sentence\n",
        "\n",
        "\n",
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be \n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens = max_vocab_length,\n",
        "                                   output_mode = \"int\",\n",
        "                                   output_sequence_length= max_length)\n",
        "\n",
        "\n",
        "\n",
        "# Fit the text vectorizer  to the training text \n",
        "# that convert our words data to numeric format \n",
        "text_vectorizer.adapt(train_sentences)\n",
        "\n",
        "# Create a sample sentences and tokenize it \n",
        "sample_sentence = \"There's a flood in my street !\"\n",
        "text_vectorizer([sample_sentence])\n",
        "\n",
        "# Choose a random sentence from the training dataset and tokenize it \n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Origina text:\\n{random_sentence}\\\n",
        "\\n\\n Vectorized version:\")\n",
        "text_vectorizer([random_sentence])\n",
        "\n",
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in our training data\n",
        "top_5_words = words_in_vocab[:5] # get the most common words\n",
        "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"5 most common words: {top_5_words}\")\n",
        "print(f\"5 least common words: {bottom_5_words}\")\n",
        "\n",
        "\n",
        "# ## Creating an Embedding using an Embedding Layer\n",
        "# \n",
        "#     To make our embedding, we re going to use TensorFlow's embedding layer : https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "#     The parameters we xare most about for our embedding layer:\n",
        "#     *`input_dim` = the size of our vocabulary\n",
        "#     *`output_dim` = the size of the output embedding vector, for example, a value of 100 could mean each token gets represented by a vector 100 long\n",
        "#     * `input_length` = length of the sequences being passed to the embedding layer\n",
        "\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128,\n",
        "                             embeddings_initializer=\"uniform\",\n",
        "                             input_length=max_length)\n",
        "embedding\n",
        "\n",
        "# Get a random sentence from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "\\n\\n Embedded version :\")\n",
        "# Embed the random sentence (turn it into danse victors of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "\n",
        "#sample_embed = tf.reshape(sample_embed, (1, 15, 128))\n",
        "sample_embed\n",
        "\n",
        "\n",
        "# Check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence\n",
        "\n",
        "\n",
        "# ## Modelling a text dateset (running a series of experimente)\n",
        "# \n",
        "#     Now we ve a got way to turn our text sequences into numbers,\n",
        "#     it's time to start building a series of modelling experiments.\n",
        "# \n",
        "#     We'll start with a baseline and moce on from there.\n",
        "# \n",
        "# * Model 0: Naive Bayes (baseline) with sklearn : https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
        "# * Model 1: Feed-forward neural network (danse model)\n",
        "# * Model 2 : LSTM model (RNN)\n",
        "# * model 3 : GRU model (RNN)\n",
        "# * model 4 : Bidirectional-LSTM model (RNN)\n",
        "# * Model 5 : 1D Convolutional Neural Network (CNN)\n",
        "# * Model 6 : TensorFlow Hub Pretrained Feature Extractor (using transfer learning for NLP)\n",
        "# * Model 7 : Same as model 6 with 10% of training data\n",
        "# \n",
        "# How are we going to approch all of these ?\n",
        "# \n",
        "# Use the standard steps in modelling with tensorflow:\n",
        "# \n",
        "# * Create a model \n",
        "# * Build a model\n",
        "# * Fit a model\n",
        "# * Evaluate model\n",
        "\n",
        "# ### Model 0 : Getting a baseline\n",
        "# \n",
        "# As with all machine learning modelling experiments, it's important to create a baseline model so you're got a benchmark for future experiments to build upon.\n",
        "# \n",
        "# To create our baseline, we'll use Sklearn's Multinomial Naive Bayers using the TF-IDF formula to convert our words to numbers\n",
        "# \n",
        "# >** note : ** it's common practice to use non-Deep Learning Algorithms as a baseline because of their speed and then later using Deep Learning to to see if you can imporove upon them.\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline ([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text clf : juste classification\n",
        "])\n",
        "\n",
        "# Fit the pipleine to the training data\n",
        "model_0.fit(train_sentences, train_labels)\n",
        "\n",
        "\n",
        "# Evaluate the baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achives an accuracy of : {baseline_score}\")\n",
        "\n",
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:10]\n",
        "# for i in range(0,10,1):\n",
        "#     print(f\" {val_sentences[i]} \\n prediction : {baseline_preds[i]}\")\n",
        "    \n",
        "\n",
        "\n",
        "# ### Creating an evaluation function for our model experiments\n",
        "# \n",
        "# We could evaluate all of our model's predictions with different metrics every time, however this will be cumbersome and could easily be fixed with function\n",
        "# \n",
        "# Let's create one to compare our model's predictions with the truth labels using the following metrics:\n",
        "# * Accuracy.\n",
        "# * Precision.\n",
        "# * Recall\n",
        "# * F1-score\n",
        "# \n",
        "# For a deep overview of many different evaluation methods, see the sklearn\n",
        "\n",
        "# ### \n",
        "\n",
        "\n",
        "# Function to evaluate : accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "# rajouter\n",
        "def calculate_results(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "    \"\"\"\n",
        "    # Calculate model accuracy\n",
        "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "    # Calculate model precision, recall and f1-score using \"weighted\" average\n",
        "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "    model_results = {\"accuracy\": model_accuracy,\n",
        "                    \"precision\": model_precision,\n",
        "                    \"recall\": model_recall,\n",
        "                    \"f1\": model_f1}\n",
        "    return model_results\n",
        "\n",
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results\n",
        "\n",
        "\n",
        "# # Model 1: A simple dense model\n",
        "\n",
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\"\n",
        "\n",
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional string\n",
        "x = text_vectorizer(inputs)# turn the input text into numbers\n",
        "x = embedding(x) # transform the input numbers in embedding\n",
        "x = layers.GlobalAveragePooling1D()(x) # Condense the feature vector for each token to on vector\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # Create the output layer, want binary outputs\n",
        "model_1 = tf.keras.Model(inputs,outputs, name=\"Model_1_dense\")\n",
        "\n",
        "\n",
        "model_1.summary()    \n",
        "\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "               optimizer=tf.keras.optimizers.Adam(),\n",
        "               metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "history_model_1 = model_1.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences,val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                        experiment_name=\"model_1_dense\")])\n",
        "\n",
        "\n",
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)\n",
        "\n",
        "\n",
        "\n",
        "# Make some predictions\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape, model_1_pred_probs[0]\n",
        "\n",
        "\n",
        "# Look at a single prediction\n",
        "model_1_pred_probs[:10]\n",
        "\n",
        "model_1_pred_probs.shape\n",
        "\n",
        "\n",
        "\n",
        "# Convert model prediction probabilities to label format\n",
        "\n",
        "model_1_pred_probs = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_pred_probs[:20]\n",
        "\n",
        "\n",
        "# Calculate our model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                   y_pred=model_1_pred_probs)\n",
        "model_1_results\n",
        "\n",
        "\n",
        "baseline_results\n",
        "\n",
        "\n",
        "# compare witch best between our models\n",
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values())) \n",
        "\n",
        "\n",
        "# ## Visualizing learned embeddings\n",
        "# \n",
        "\n",
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]\n",
        "\n",
        "\n",
        "\n",
        "max_vocab_length\n",
        "\n",
        "# Model 1 summary\n",
        "model_1.summary()\n",
        "\n",
        "\n",
        "# Get the weight matrix of embedding layer\n",
        "# (thse are the numerical representations of each token in our training data, which have been learned for -5 epochs)\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()\n",
        "print(embed_weights[0].shape) # same size as vocab size and embedding_dim (output_dim of our embedding layer)\n",
        "\n",
        "\n",
        "embed_weights\n",
        "\n",
        "\n",
        "# Now we've got the embedding matric our model has learned to represent our tokens, let's see how we can visualize it.\n",
        "# \n",
        "# To do so, TensorFlow has a handly tool called projector: https://projector.tensorflow.org/\n",
        "# \n",
        "# And TensorFlow also has an incredible guide on word embeddings themselves\n",
        "# https://www.tensorflow.org/text/guide/word_embeddings\n",
        "\n",
        "\n",
        "# # Create embedding files (we got this from TensorFlow's word embedding documentation)\n",
        "# import io\n",
        "# out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "# out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "# for index, word in enumerate(words_in_vocab):\n",
        "#   if index == 0:\n",
        "#     continue  # skip 0, it's padding.\n",
        "#   vec = embed_weights[0][index]\n",
        "#   out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "#   out_m.write(word + \"\\n\")\n",
        "# out_v.close()\n",
        "# out_m.close()\n",
        "\n",
        "\n",
        "# try:\n",
        "#   from google.colab import files\n",
        "#   files.download('vectors.tsv')\n",
        "#   files.download('metadata.tsv')\n",
        "# except Exception:\n",
        "#   pass\n",
        "\n",
        "\n",
        "# Downloading the files above can visualize them usign http://projector.tensorflow.org/ and clicking the \"load\" button on the left hand\n",
        "# *Ressources : if you'd like to know more about embedding, I'd encourage you to check out :\n",
        "# - Jay Alammer's vusualized word2vec post : https://jalammar.github.io/illustrated-word2vec/\n",
        "# - TensorFlow's Word Embeddings guide: https://www.tensorflow.org/tutorials/text/word_embeddings\n",
        "\n",
        "# ## Recurrent Neural Networks (RNN's)\n",
        "# \n",
        "# RNN's are useful for sequence data.\n",
        "# \n",
        "# The premise of a recurrent neural network is to use the representation of a previous input to aid the representation of a later\n",
        "# * Ressources :> \n",
        "# If you want an overview of the internale of a recurrent neural network, see the following : \n",
        "#     - MIT's sequence modelling lecture https://www.youtube.com/watch?v=QvkQ1B3FBqA\n",
        "#     - Chris Olah's intro to LSTMs : https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "#     - Andrej Karphathy's the unreasonable effectiveness of recurrent neural network : http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
        "#     - https://www.youtube.com/watch?v=QvkQ1B3FBqA&t=166s\n",
        "\n",
        "# ### Model 2 : LSTM \n",
        "# LSTM = long short term memory (one of the most popular LSTM cells)\n",
        "# \n",
        "# Our structure of an RNN Typically looks like this:\n",
        "# \n",
        "# ```\n",
        "# Input (text) -> Tokenize -> Embedding -> Layers (RNNs/dense) -> Output (label probability)\n",
        "# ```\n",
        "\n",
        "# Create an LSTM model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# print(x.shape)\n",
        "# x = layers.LSTM(units=64, return_sequences=True)(x) # when you're stacking RNN cells together, you need to  returns sequences=True\n",
        "# print(x.shape)\n",
        "x = layers.LSTM(64, activation=\"relu\")(x)\n",
        "# print(x.shape)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "# print(x.shape)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n",
        "\n",
        "\n",
        "# Get the summary \n",
        "model_2.summary()\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# Fit the model \n",
        "history_model2 = model_2.fit(train_sentences,\n",
        "                            train_labels,\n",
        "                            epochs=5,\n",
        "                            validation_data=(val_sentences,val_labels),\n",
        "                            callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                   experiment_name=\"model_2_LSTM\")]) \n",
        "\n",
        "\n",
        "\n",
        "# Make prediction with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]\n",
        "\n",
        "\n",
        "# Convert model 2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs)) # enlever les dimension en plus\n",
        "model_2_preds[:10]\n",
        "\n",
        "\n",
        "# Calculate model 2 results\n",
        "model_2_results = calculate_results(val_labels, model_2_preds)\n",
        "model_2_results\n",
        "\n",
        "baseline_results\n",
        "\n",
        "np.array(list(model_1_results.values())) > np.array(list(model_2_results.values()))  \n",
        "\n",
        "\n",
        "# ### Model 3 : GRU\n",
        "# \n",
        "# Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
        "# \n",
        "# The GRU cell has similar features to an LSTM cell but has less parameters.\n",
        "\n",
        "# Build an RNN GRU\n",
        "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = tf.keras.layers.GRU(3)(x)\n",
        "# x = tf.keras.layers.GRU(units=64, return_sequences=True)(x) \n",
        "# x = tf.keras.layers.LSTM(42, return_sequences=True)(x)\n",
        "# x = tf.keras.layers.GRU(units=92, return_sequences=True)(x)\n",
        "\n",
        "# # Apply global average pooling\n",
        "# x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "# x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")\n",
        "\n",
        "# # Version 2\n",
        "# # Build an RNN GRU\n",
        "# inputs = tf.keras.layers.Input(shape=(1), dtype=tf.string)\n",
        "# x = text_vectorizer(inputs)\n",
        "# x = embedding(x)\n",
        "# # x = tf.keras.layers.GRU(64)(x)\n",
        "# x = tf.keras.layers.GRU(units=64, return_sequences=True)(x) \n",
        "# x = tf.keras.layers.LSTM(42, return_sequences=True)(x)\n",
        "# x = tf.keras.layers.GRU(units=92, return_sequences=True)(x)\n",
        "\n",
        "# # Apply global average pooling\n",
        "# x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "# x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
        "# outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "# model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")\n",
        "\n",
        "\n",
        "# Get a summary\n",
        "model_3.summary()\n",
        "\n",
        "# compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "               optimizer=tf.keras.optimizers.Adam(),\n",
        "               metrics=[\"accuracy\"])\n",
        "\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences,val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                        experiment_name=\"model_3_GRU\")])\n",
        "\n",
        "\n",
        "# Make som prediction with our GRU model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "\n",
        "\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "\n",
        "\n",
        "model_3_results = calculate_results(val_labels, model_3_preds)\n",
        "model_3_results\n",
        "\n",
        "# comparing model 1 with model 2\n",
        "np.array(list(model_1_results.values())) > np.array(list(model_3_results.values()))  \n",
        "\n",
        "\n",
        "# # Mode 4 :  Bidirectional RNN\n",
        "# \n",
        "# \n",
        "\n",
        "# create the model\n",
        "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, activation=\"relu\"))(x)\n",
        "# x = tf.keras.layers.AveragePooling1D()(x)\n",
        "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional_layer\")\n",
        "\n",
        "\n",
        "model_4.summary()\n",
        "\n",
        "\n",
        "\n",
        "model_4_predict_prob = tf.squeeze(model_4.predict(val_sentences))\n",
        "model_4_preds = tf.round(model_4_predict_prob)\n",
        "\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results\n",
        "\n",
        "\n",
        "# # Model 4 : Bidirectional RNN\n",
        "# \n",
        "# Normal RNN's go from left to right (just like you'd read an English sentence), however, bidirectional RNN goes from right to left as well as left to right.\n",
        "# \n",
        "# \n",
        "\n",
        "\n",
        "# Build a bidirectional RNN in TensorFlow \n",
        "# create the model\n",
        "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(x)\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64))(x)\n",
        "print(x.shape) # nb_units * 2 comme c'est bidirectional\n",
        "\n",
        "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional_layer\")\n",
        "\n",
        "\n",
        "\n",
        "# Get a summary \n",
        "model_4.summary()\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model_4.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "               optimizer=tf.keras.optimizers.Adam(),\n",
        "               metrics=[\"accuracy\"])\n",
        "\n",
        "history_model_4 = model_4.fit(train_sentences,\n",
        "                             train_labels,\n",
        "                             epochs=5,\n",
        "                             validation_data=(val_sentences, val_labels),\n",
        "                             callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                    experiment_name=\"Bidirectionalmod\")])\n",
        "\n",
        "\n",
        "# Make prediction with our bidirectional model\n",
        "model_4_predict_prob = tf.squeeze(model_4.predict(val_sentences))\n",
        "# Convert pred probs to labels \n",
        "model_4_preds = tf.round(model_4_predict_prob)\n",
        "\n",
        "# Convert pred probs to labels \n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results\n",
        "\n",
        "\n",
        "# ## Convolution Neural Networks for Text (and other types of sequences)\n",
        "# \n",
        "# We've used CNNs for images but images are typically 2D (geight x width)... however, our text data is 1D.\n",
        "# \n",
        "# Previously we've Conv2D for our image data but now we're going to use Conv1D.\n",
        "# \n",
        "# The typical structure of a Conv1D model for sequences (in our case, text):\n",
        "# \n",
        "# Inputs (text) -> Tokenization -> Embedding -> Layer(s) (typicallyConv1D + Pooling layer) -> Pooling -> Outputs (class probabilities) \n",
        "\n",
        "# ## Model 5 : Conv1D\n",
        "# \n",
        "# For different explanations of parameters see:\n",
        "# * https://poloclub.github.io/cnn-explainer/\n",
        "# * Difference between \"same\" and \"valid\" padding:https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t#:~:text=To%20sum%20up%2C%20'valid',same'%20padding%20means%20using%20padding.\n",
        "\n",
        "\n",
        "\n",
        "# embedding_test = embedding(text_vectorizer([\"c est test de phrase\"]))\n",
        "# conv_1d = tf.keras.layers.Conv1D(filters=32,\n",
        "#                                  kernel_size=5 , \n",
        "#                                  activation=\"relu\",\n",
        "#                                  padding=\"valid\")\n",
        "# conv_1d_output = conv_1d(embedding_test) # pass test embedding through conv1d layer\n",
        "# max_pool = tf.keras.layers.GlobalAvgPool1D()\n",
        "# max_pool_output = max_pool(conv_1d_output) # equivalent to \"get the most important feature\" or \"get the feature with the highest value\"\n",
        "\n",
        "# embedding_test.shape, conv_1d_output.shape, max_pool_output.shape\n",
        "# # embedding_test\n",
        "# # conv_1d_output\n",
        "# # max_pool_output\n",
        "\n",
        "\n",
        "\n",
        "# Test out our embedding layer, Conv1D layer and max pooling\n",
        "inputs = tf.keras.layers.Input(shape=(1), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = tf.keras.layers.Conv1D(filters=64,\n",
        "                           kernel_size=5 , \n",
        "                           activation=\"relu\",\n",
        "                           strides=1,\n",
        "                           padding=\"valid\")(x)\n",
        "x = tf.keras.layers.GlobalAvgPool1D()(x)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1d\")\n",
        "\n",
        "model_5.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "# Get a summary of our Conv1D model\n",
        "model_5.summary()\n",
        "\n",
        "\n",
        "\n",
        "model_5.fit(train_sentences,\n",
        "            train_labels,\n",
        "            epochs=5,\n",
        "            validation_data=(val_sentences, val_labels),\n",
        "            callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                 experiment_name=\"model_5_Conv1d\")])\n",
        "\n",
        "\n",
        "\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs\n",
        "# convert model_5_pred_probs to labels 0 or 1\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "# model_5_preds\n",
        "\n",
        "\n",
        "model_5_results = calculate_results(val_labels, model_5_preds)\n",
        "model_5_results\n",
        "\n",
        "\n",
        "# Check witch the best \n",
        "np.array(list(model_5_results.values())) > np.array(list(baseline_results.values()))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
        "Now we've built a few of our own models, let's try and use transfer learning for NLP, specifically using TensorFlow Hub's Universal Sentence Encoder : https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "\n",
        "See how the USE was created  here : https://arxiv.org/abs/1803.11175 "
      ],
      "metadata": {
        "id": "qQkZ3tAX1mFt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZxkdJswlPuI3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# turn dataframe values to dataframe columns\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                    train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                    test_size = 0.1, # use 10% of traianing data for validations\n",
        "                                                    random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnzhcfSDFhR6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8HOKv_LhBe_Q"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "# Create a Keras Layer using the USE pretrained layer from tensorflow hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[],\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name=\"USE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0R1SaLanEHMz",
        "outputId": "a7f1866c-e682-45f7-dea0-0fd913f98fce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_6_tf_hub/20230125-202952\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 13ms/step - loss: 0.5023 - accuracy: 0.7897 - val_loss: 0.4461 - val_accuracy: 0.8031\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.4134 - accuracy: 0.8151 - val_loss: 0.4374 - val_accuracy: 0.8110\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.4002 - accuracy: 0.8203 - val_loss: 0.4328 - val_accuracy: 0.8097\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.3921 - accuracy: 0.8272 - val_loss: 0.4281 - val_accuracy: 0.8110\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.3847 - accuracy: 0.8302 - val_loss: 0.4239 - val_accuracy: 0.8189\n"
          ]
        }
      ],
      "source": [
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Train a classifier on top of USE pretrained embeddings\n",
        "history_model_6 = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                            callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                  experiment_name=\"model_6_tf_hub\")])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5NmFixRQJflt",
        "outputId": "02ef28eb-4f1e-471e-e7cc-c371ea1b3660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_6.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6mwigehmTB6r",
        "outputId": "9f70b918-0fcc-4310-d48e-9efd2cb0c71b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 14ms/step\n"
          ]
        }
      ],
      "source": [
        "# Make prediction with USE TF Hub Model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs)) # transforme to labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y4gKxvmfUMkK",
        "outputId": "afa1901a-326b-4e98-bb11-8a8df31b7583"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 81.88976377952756,\n",
              " 'precision': 0.8203089036947304,\n",
              " 'recall': 0.8188976377952756,\n",
              " 'f1': 0.8177314483416845}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate model_6 performance metrics\n",
        "model_6_results = calculate_results(val_labels,model_6_preds)\n",
        "model_6_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4vQnGtwYU9jT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oTzJ9UuCWp_i",
        "outputId": "940969d0-66bd-4989-dd19-06d16eab1784"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7613"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K29KZvV-csaF"
      },
      "source": [
        "## Model 7: TF Hub Pretrained USE but with 10% of training data\n",
        "Transfer learning really helps when you don't have a large dataset.\n",
        "\n",
        "To see how our modeel performs on a smaller dataset, let's replicate model _6 except we'll train it on 10% of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeiBgkENF7aJ"
      },
      "outputs": [],
      "source": [
        "# ## NOTE : making data splits like below leads to data leakage (model_7 trzined on 10%, out performs model_6 trained on 100% data)\n",
        "# ## DO NOT MAKE DATA SPLITS WHICH LEAK DATA FROM VALIDATION/TEST INTO TRAINING SET\n",
        "\n",
        "# # Create subset of 10% of the training data\n",
        "# train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
        "# # train_10_percent.head(), len(train_10_percent)\n",
        "# train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
        "# train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
        "\n",
        "# # len of train_sentences_10_percent and train_labels_10_percent\n",
        "# print(f\"len of train_sentences_10_percent : {len(train_sentences_10_percent)}\")\n",
        "# print(f\"len of train_labels_10_percent    : {len(train_labels_10_percent)}\\n\")\n",
        "\n",
        "# # Check the number of targets in our subset of data\n",
        "# print(\"number of targets in our train_10_percent :\")\n",
        "# print(train_10_percent[\"target\"].value_counts())\n",
        "\n",
        "# print(\"number of targets in our train_df_shuffled :\")\n",
        "# print(train_df_shuffled[\"target\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PX_w8pnaNv9"
      },
      "source": [
        "To recreate a model the same as a previous model you've created you van use the `tf.keras.models/clone_model()` method, see more here : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_Ivhy9yc26J"
      },
      "outputs": [],
      "source": [
        "# # Let's build a model same as model_6\n",
        "# model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# # compile the model\n",
        "# model_7.compile(loss=\"binary_crossentropy\",\n",
        "#                 optimizer=tf.keras.optimizers.Adam(),\n",
        "#                 metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYL_IpulPZaJ"
      },
      "outputs": [],
      "source": [
        "# # fit the data with incorrect split\n",
        "\n",
        "# # fit the model with 10% percent data\n",
        "# history_model_7_incorrect = model_7.fit(train_sentences_10_percent,\n",
        "#                                         train_labels_10_percent,\n",
        "#                                         epochs=5,\n",
        "#                                         validation_data=(val_sentences,val_labels),\n",
        "#                                         callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "#                                                                                experiment_name=\"tf_hub_sentence_encoder_10_percent_incorrect\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR365PqeQeZH"
      },
      "outputs": [],
      "source": [
        "# # predict the model\n",
        "# model_7_pred_probs = model_7.predict(val_sentences)\n",
        "\n",
        "# print(f\"model_7_predict_probs[:10] : \\n{model_7_pred_probs[:10]}\\n\")\n",
        "\n",
        "# # Turn pred probs into labels\n",
        "# model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "# print(f\"model_7_preds[:10] (labels): \\n{model_7_preds[:10]}\\n\")\n",
        "\n",
        "# # calcule results model evaluation\n",
        "# model_7_incorrect_results = calculate_results(val_labels, model_7_preds)\n",
        "# print(f\"model_7_incorrect_results : \\n{model_7_incorrect_results}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38Nj8PO4doAp",
        "outputId": "436a5594-6a62-4e9a-9783-14593a665e6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(train_labels_10_percent) : 685\n",
            "\n",
            "number of each label in the updated training data subset :\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0    406\n",
              "1    279\n",
              "dtype: int64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Correct data split\n",
        "# Making a better dataset split (no data leakage\n",
        "# recup 10 percent of our previous split data train\n",
        "train_10_percent_split = int(0.1*len(train_sentences))\n",
        "# une technique plutot sympa\n",
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]\n",
        "print(f\"len(train_labels_10_percent) : {len(train_labels_10_percent)}\\n\")\n",
        "\n",
        "# Check the number of each label in the updated training data subset\n",
        "print(\"number of each label in the updated training data subset :\")\n",
        "pd.Series(np.array(train_labels_10_percent)).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usqZg50lU-Ij"
      },
      "outputs": [],
      "source": [
        "# Let's build a model same as model_6\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# compile the model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxEym9i3Vm_K",
        "outputId": "c8540c5a-484f-445f-d417-7fca66fa8430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent_correct/20230117-155117\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 4s 45ms/step - loss: 0.6627 - accuracy: 0.6409 - val_loss: 0.6395 - val_accuracy: 0.7060\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.5868 - accuracy: 0.7869 - val_loss: 0.5806 - val_accuracy: 0.7612\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.5125 - accuracy: 0.8161 - val_loss: 0.5314 - val_accuracy: 0.7822\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 0.4557 - accuracy: 0.8146 - val_loss: 0.5031 - val_accuracy: 0.7782\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.4181 - accuracy: 0.8277 - val_loss: 0.4906 - val_accuracy: 0.7848\n"
          ]
        }
      ],
      "source": [
        "# fit the model with 10% percent data\n",
        "history_model_7 = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences,val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                    experiment_name=\"tf_hub_sentence_encoder_10_percent_correct\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CWDu_9GyIrS",
        "outputId": "a9969d20-ba26-4944-8eb5-a8d4b126b922"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 11ms/step\n",
            "model_7_predict_probs[:10] : \n",
            "[[0.18132102]\n",
            " [0.57961   ]\n",
            " [0.9068097 ]\n",
            " [0.32180348]\n",
            " [0.54446566]\n",
            " [0.65905774]\n",
            " [0.8837333 ]\n",
            " [0.82229495]\n",
            " [0.8453111 ]\n",
            " [0.13688931]]\n",
            "\n",
            "model_7_preds[:10] (labels): \n",
            "[0. 1. 1. 0. 1. 1. 1. 1. 1. 0.]\n",
            "\n",
            "model_7_results : \n",
            "{'accuracy': 78.4776902887139, 'precision': 0.7870511640590381, 'recall': 0.7847769028871391, 'f1': 0.7827022002767159}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# predict the model\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "print(f\"model_7_predict_probs[:10] : \\n{model_7_pred_probs[:10]}\\n\")\n",
        "\n",
        "# Turn pred probs into labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "print(f\"model_7_preds[:10] (labels): \\n{model_7_preds[:10]}\\n\")\n",
        "\n",
        "# calcule results model evaluation\n",
        "model_7_results = calculate_results(val_labels, model_7_preds)\n",
        "print(f\"model_7_results : \\n{model_7_results}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNdrb_9nRgm3"
      },
      "outputs": [],
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                \"1_simple_dense\": model_1_results,\n",
        "                                \"2_lstm\":model_2_results,\n",
        "                                \"3_gru\":model_3_results,\n",
        "                                \"4_bidirectional\": model_4_results,\n",
        "                                \"5_conv1d\": model_5_results,\n",
        "                                \"6_tf_hub_use_encoder\": model_6_results,\n",
        "                                \"7_tf_hub_use_encoder_10_percent\": model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "# Reduce the accuracy to the same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "K6z5-WsARx9A",
        "outputId": "b1ab3c06-b82d-4ae8-9884-8b11b531ba08"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-52a16eb0-9fb7-4c44-b52c-884eada82ca9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>0.786089</td>\n",
              "      <td>0.792092</td>\n",
              "      <td>0.786089</td>\n",
              "      <td>0.782703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_lstm</th>\n",
              "      <td>0.771654</td>\n",
              "      <td>0.771482</td>\n",
              "      <td>0.771654</td>\n",
              "      <td>0.770792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_gru</th>\n",
              "      <td>0.772966</td>\n",
              "      <td>0.773053</td>\n",
              "      <td>0.772966</td>\n",
              "      <td>0.771872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.781115</td>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.777651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1d</th>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.766590</td>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.765121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_use_encoder</th>\n",
              "      <td>0.804462</td>\n",
              "      <td>0.804290</td>\n",
              "      <td>0.804462</td>\n",
              "      <td>0.804341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
              "      <td>0.784777</td>\n",
              "      <td>0.787051</td>\n",
              "      <td>0.784777</td>\n",
              "      <td>0.782702</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52a16eb0-9fb7-4c44-b52c-884eada82ca9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52a16eb0-9fb7-4c44-b52c-884eada82ca9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52a16eb0-9fb7-4c44-b52c-884eada82ca9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                 accuracy  precision    recall        f1\n",
              "baseline                         0.792651   0.811139  0.792651  0.786219\n",
              "1_simple_dense                   0.786089   0.792092  0.786089  0.782703\n",
              "2_lstm                           0.771654   0.771482  0.771654  0.770792\n",
              "3_gru                            0.772966   0.773053  0.772966  0.771872\n",
              "4_bidirectional                  0.779528   0.781115  0.779528  0.777651\n",
              "5_conv1d                         0.766404   0.766590  0.766404  0.765121\n",
              "6_tf_hub_use_encoder             0.804462   0.804290  0.804462  0.804341\n",
              "7_tf_hub_use_encoder_10_percent  0.784777   0.787051  0.784777  0.782702"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_model_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "jze3K8VSRhb1",
        "outputId": "e62730b4-e6ea-42d2-8447-8c305aa37816"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10,7)).legend(bbox_to_anchor=(1.0,1.0));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eP6VgcrmRhlk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYbXU9gORhr-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBxtXixaRhxf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsxtZ2NqRh19"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzYypwLX9wEu"
      },
      "outputs": [],
      "source": [
        "# !tensorboard dev upload --logdir model_logs\\\n",
        "#     --name \"models experiments\" \\\n",
        "#     --description \"Simple comparison of differents models of RNN\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PexqP8mMlhBH"
      },
      "source": [
        "Now I've ran the cell above, my modelling experiments are visible on TensorBoard.dev: https://tensorboard.dev/experiment/D50zrynvRmC44evTdw1YYg/\n",
        "\n",
        "> Ressource: TensorBoard is great for quickly tracking experiments but for larger scale experiments and a whole bunch more tracking options, check options,  check out Weights & Biases https://wandb.ai/site"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzCRaEuNwVDJ"
      },
      "outputs": [],
      "source": [
        "# See the previous TensorBoard Dev experiments you've run...\n",
        "#!tensorboard dev list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sy37vU2Kkdj7"
      },
      "outputs": [],
      "source": [
        "# If you need to delete an experiment from TensorBoard, you can run the following:\n",
        "# !tensorboard dev delete --experiment_id D50zrynvRmC44evTdw1YYg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QUjL_Zzgeit",
        "outputId": "0e6ba662-b405-4255-d326-9008d146d10a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        }
      ],
      "source": [
        "# save the model\n",
        "\n",
        "#model_0.save(\"save_models/model_0.H5\")\n",
        "#model_1.save(\"save_models/model_1.H5\")\n",
        "#model_2.save(\"save_models/model_2.H5\")\n",
        "#model_3.save(\"save_models/model_3.H5\")\n",
        "#model_4.save(\"save_models/model_4.H5\")\n",
        "#model_5.save(\"save_models/model_5.H5\")\n",
        "model_6.save(\"save_models/model_6.H5\")\n",
        "#model_7.save(\"save_models/model_7.H5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5j3zSBFkCuU"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "loaded_model_6 = tf.keras.models.load_model(\"drive/MyDrive/save_models/model_6.H5\",\n",
        "                                     custom_objects={\"KerasLayer\": hub.KerasLayer})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV_zb7tbklwO",
        "outputId": "cccb4e50-a4d0-4f5c-9701-fe07ca777e8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 2s 10ms/step - loss: 0.4253 - accuracy: 0.8202\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.4252946376800537, 0.8202099800109863]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# How does our loaded model perform?\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsI8G634mkdF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BFpeViWkwXu"
      },
      "outputs": [],
      "source": [
        "# Save TF Hub sentence Encoder Model to savedModel format (default)\n",
        "#model_6.save(\"model_6_SaveModel_format\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec8NlLhLmfBY"
      },
      "outputs": [],
      "source": [
        "# Load in a model from the SavedModel format\n",
        "#loaded_model_6_SavedModel_format = tf.keras.models.load_model(\"model_6_SaveModel_format\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COfzrhpom6J6"
      },
      "outputs": [],
      "source": [
        "# Download a file with google colab\n",
        "# from google.colab import files\n",
        "# files.download(\"example.txt \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn3PNWuGnzrF"
      },
      "source": [
        "## Finding the most wrong examples\n",
        "\n",
        "* If our best model still isn't perfect, what examples is it getting wrong?\n",
        "* And of these wrong examples which ones is it getting  *most* wrong (those with prediction probabilities )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yIRdvs8nCPq"
      },
      "outputs": [],
      "source": [
        "## Finding the most wrong examples\n",
        "from helper_functions import make_confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNocuqSLs5uh",
        "outputId": "2c1b5615-98fb-473d-ed33-d6d9ad29cc16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-01-17 20:26:22--  https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.99.128, 173.194.202.128, 74.125.20.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.99.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 960779165 (916M) [application/zip]\n",
            "Saving to: ‘08_model_6_USE_feature_extractor.zip’\n",
            "\n",
            "08_model_6_USE_feat 100%[===================>] 916.27M   141MB/s    in 8.9s    \n",
            "\n",
            "2023-01-17 20:26:31 (103 MB/s) - ‘08_model_6_USE_feature_extractor.zip’ saved [960779165/960779165]\n",
            "\n",
            "Archive:  08_model_6_USE_feature_extractor.zip\n",
            "   creating: 08_model_6_USE_feature_extractor/\n",
            "   creating: 08_model_6_USE_feature_extractor/assets/\n",
            "   creating: 08_model_6_USE_feature_extractor/variables/\n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.data-00000-of-00001  \n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.index  \n",
            "  inflating: 08_model_6_USE_feature_extractor/saved_model.pb  \n"
          ]
        }
      ],
      "source": [
        "# Download a pretrained model from google storage\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
        "!unzip 08_model_6_USE_feature_extractor.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8kFGG2ftg8q",
        "outputId": "a4df079a-b67f-4dc1-bee8-557944bd75df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        }
      ],
      "source": [
        "# Import previously trained model from google Storage\n",
        "model_6_pretrained = tf.keras.models.load_model(\"08_model_6_USE_feature_extractor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1NElo36bO8z",
        "outputId": "20f66dcf-7e1d-48a7-cbb5-3e4f3d538c84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 10ms/step - loss: 0.4272 - accuracy: 0.8163\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.42723122239112854, 0.8162729740142822]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_6_pretrained.evaluate(val_sentences,val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCADxgnIbkFn",
        "outputId": "9eddbbc5-fce4-4f8b-f6eb-f9e9f63004ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 10ms/step\n"
          ]
        }
      ],
      "source": [
        "# Make predictions with the loaded model from GS\n",
        "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences) \n",
        "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MTUU4b1NbwOo",
        "outputId": "9b4a434c-b0fc-45d1-f53a-16d19c19ed4b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-096e8424-f7b9-4ed7-becc-998c2b2930a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_probs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.747162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.196229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.707808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-096e8424-f7b9-4ed7-becc-998c2b2930a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-096e8424-f7b9-4ed7-becc-998c2b2930a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-096e8424-f7b9-4ed7-becc-998c2b2930a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  target  pred  pred_probs\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0    0.159757\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0    0.747162\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0    0.988749\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0    0.196229\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0    0.707808"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create DataFrame with validation sentences, validation labels and best performing model prediction label + probabilities\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_pretrained_preds,\n",
        "                       \"pred_probs\": tf.squeeze((model_6_pretrained_pred_probs))})\n",
        "val_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykkirEhuqy1C"
      },
      "outputs": [],
      "source": [
        "# Create DataFrame with validation sentences and best performing model predictions\n",
        "# make_confusion_matrix(y_true=val_labels,y_pred=model_6_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gFQzLAL7rKsP",
        "outputId": "e097969d-df6a-4099-cc17-56b6769e8d5c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3930f06a-90b9-4f31-965a-af3dedd93a2c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_probs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.876982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.835454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.827213</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3930f06a-90b9-4f31-965a-af3dedd93a2c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3930f06a-90b9-4f31-965a-af3dedd93a2c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3930f06a-90b9-4f31-965a-af3dedd93a2c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  text  target  pred  \\\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   \n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   \n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   \n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   \n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   \n",
              "\n",
              "     pred_probs  \n",
              "31     0.910196  \n",
              "759    0.876982  \n",
              "628    0.852300  \n",
              "209    0.835454  \n",
              "251    0.827213  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_probs\", ascending=False) \n",
        "most_wrong.head() # These are false positive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgW-Okn9mhy-"
      },
      "source": [
        "Let's remind ourselves of the target labels...\n",
        "* `0` = not disaster\n",
        "* `1` = disaster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "T0a0MbSGkrsg",
        "outputId": "9af9d1c1-4d40-4b37-ece7-89a3fa98bea4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c90c36ed-fb75-4bf4-bfb8-1b6f6a89dc9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_probs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>I get to smoke my shit in peace</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Why are you deluged with low self-image? Take ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c90c36ed-fb75-4bf4-bfb8-1b6f6a89dc9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c90c36ed-fb75-4bf4-bfb8-1b6f6a89dc9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c90c36ed-fb75-4bf4-bfb8-1b6f6a89dc9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  text  target  pred  \\\n",
              "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   \n",
              "233                    I get to smoke my shit in peace       1   0.0   \n",
              "38   Why are you deluged with low self-image? Take ...       1   0.0   \n",
              "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1   0.0   \n",
              "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   \n",
              "\n",
              "     pred_probs  \n",
              "411    0.043918  \n",
              "233    0.042087  \n",
              "38     0.038998  \n",
              "244    0.038949  \n",
              "23     0.037186  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "most_wrong.tail() # The are false negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg_IKyI9nF1w",
        "outputId": "f4022826-a8b5-4053-b57a-b519fe220892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target : 0, Pred: 1.0, Prob:0.9101957678794861\n",
            "text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.8769821524620056\n",
            "text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.8523000478744507\n",
            "text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.8354544639587402\n",
            "text:\n",
            "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.8272132873535156\n",
            "text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.8148158192634583\n",
            "text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.8108396530151367\n",
            "text:\n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.8031217455863953\n",
            "text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.7669008374214172\n",
            "text:\n",
            "@freefromwolves GodsLove &amp; #thankU brother Danny for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.7666252255439758\n",
            "text:\n",
            "Air Group is here to the rescue! We have 24/7 Emergency Service! Learn more about it here - http://t.co/9lyx7zMtHE http://t.co/5PbC96rTMJ\n",
            "\n"
          ]
        }
      ],
      "source": [
        "  # Check the false postive (model predicted 1 when should've been 0)\n",
        "  for row in  most_wrong[:10].itertuples():\n",
        "    _, text, target, pred, pred_prob = row\n",
        "    print(f\"Target : {target}, Pred: {pred}, Prob:{pred_prob}\")\n",
        "    print(f\"text:\\n{text}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHd0mAz0qhtm",
        "outputId": "ea143ef0-1fda-4b86-8cdf-d02e16517175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target : 0, Pred: 1.0, Prob:0.9101957678794861\n",
            "text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.8769821524620056\n",
            "text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.8523000478744507\n",
            "text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.8354544639587402\n",
            "text:\n",
            "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.8272132873535156\n",
            "text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.8148158192634583\n",
            "text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.8108396530151367\n",
            "text:\n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.8031217455863953\n",
            "text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.7669008374214172\n",
            "text:\n",
            "@freefromwolves GodsLove &amp; #thankU brother Danny for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.7666252255439758\n",
            "text:\n",
            "Air Group is here to the rescue! We have 24/7 Emergency Service! Learn more about it here - http://t.co/9lyx7zMtHE http://t.co/5PbC96rTMJ\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.7626621723175049\n",
            "text:\n",
            "The Sound of Arson\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.7472230195999146\n",
            "text:\n",
            "Deaths 3 http://t.co/nApviyGKYK\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.7471620440483093\n",
            "text:\n",
            "FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps http://t.co/qZQc8WWwcN via @usatoday\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.7424103021621704\n",
            "text:\n",
            "åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Tent Collapse Story: Correction: Tent Collapse story åÈ http://t.co/fDJUYvZMrv @wizkidayo\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.7399969100952148\n",
            "text:\n",
            "A look at state actions a year after Ferguson's upheaval http://t.co/GZEkQWzijq\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.7380800247192383\n",
            "text:\n",
            "The #tubestrike is because TFL workers may have trouble planning downtime. I hope none need emergency services. http://t.co/iCSFDSiFqb\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.7356608510017395\n",
            "text:\n",
            "@BrodyFrieling @hanna_brooksie photo bombed\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.716756284236908\n",
            "text:\n",
            "GENERAL AUDIENCE: On Wounded Families | ZENIT - The World Seen From Rome http://t.co/hFvnyfT78C\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.7162530422210693\n",
            "text:\n",
            "Day 2. Liquidation of emergency at chemical object. #USAR2015 #USAR15 #RUOR #??????????? http://t.co/gGTmDqUdDo\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.7122594118118286\n",
            "text:\n",
            "@RebeccaforReal accepts Wisconsin Emergency Response Plan on behalf of @GovWalker #nbc15 http://t.co/Pis0aiVRbR\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.7117385864257812\n",
            "text:\n",
            "@pxnatosil @RenuncieDilma  Fatality!\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.6949764490127563\n",
            "text:\n",
            "Trafford Centre film fans angry after Odeon cinema evacuated following false fire alarm   http://t.co/6GLDwx71DA\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.6924800276756287\n",
            "text:\n",
            "Article by Michael Jackman at Metro Times Detroit:\n",
            "The group later downgraded the estimate to 37 square miles of... http://t.co/h31mmuduqt\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.6918948292732239\n",
            "text:\n",
            ".@AIGinsurance CEO: Divestitures and #Catastrophe Losses Temper Q2 #Results http://t.co/2y2wZk1FrM\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.688007116317749\n",
            "text:\n",
            "My phone looks like it was in a car ship airplane accident. Terrible\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.6571957468986511\n",
            "text:\n",
            "Love is the weapon for this wounded generation &lt;3\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.6566484570503235\n",
            "text:\n",
            "Cyclists it is pandemonium on the roads today. Drive carefully!\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.6561859846115112\n",
            "text:\n",
            "the windstorm blew thru my open window and now my bong is in pieces just another example of nature's indifference to human suffering\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.644920289516449\n",
            "text:\n",
            "Haley Lu Richardson Fights for Water in The Last Survivors (Review) http://t.co/oObSCFOKtQ\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.6337714791297913\n",
            "text:\n",
            "Photo: postapocalypticflimflam: Prodding around the rubble. http://t.co/Bgy4i47j70\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.6278930902481079\n",
            "text:\n",
            "@cjbanning 4sake of argsuppose pre-born has attained individl rights.Generally courtof law forbids killing unless dead person did something\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.6268865466117859\n",
            "text:\n",
            "Diageo's CEO stresses that a board revolt at United Spirits has not impacted Indian operations http://t.co/STPOdA901U\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.6126307249069214\n",
            "text:\n",
            "Crack in the path where I wiped out this morning during beach run. Surface wounds on left elbow and right knee. http://t.co/yaqRSximph\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.6044844388961792\n",
            "text:\n",
            "Do you have a plan? Emergency Preparedness for #Families of\n",
            "Children with Special Needs  http://t.co/RdOVqaUAx5  #autism #specialneeds\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.5865289568901062\n",
            "text:\n",
            "@RedCoatJackpot *As it was typical for them their bullets collided and none managed to reach their targets; such was the ''curse'' of a --\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.5798137187957764\n",
            "text:\n",
            "there's this person &amp; they reckon when you're dying your brain floods with dmt causing you to relive your life in real time in a simulation\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.5744490623474121\n",
            "text:\n",
            "He made such a good point. White person comings mass murder labelled as criminal minority does the same thing... http://t.co/37qPsSnaCv\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.5735117197036743\n",
            "text:\n",
            "Emergency Response and Hazardous Chemical Management: Principles and Practices http://t.co/4sSuyhkgRB http://t.co/TDerBtgZ2k\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.5689483880996704\n",
            "text:\n",
            "Came across this fire video not mine..enjoy..Babes way of saying hi to me while he's in the fire truck??\n",
            "#fireman #Û_ http://t.co/V5gTUnwohy\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.5630190968513489\n",
            "text:\n",
            "Public Hearing on 2015-16 @SUNY_Orange budget Thurs 8/6 at 3:15 Emergency Services Ctr Goshen. http://t.co/80DzgCo6Vc\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.5628426671028137\n",
            "text:\n",
            "#helpme what do I do? My friend has been ticketed by Police in Wayne County Michigan into never- sending poverty cycle. How do I help him?\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.5570699572563171\n",
            "text:\n",
            "Ignition Knock (Detonation) Sensor Connector-Connecto MOTORCRAFT WPT-410 http://t.co/bSmJ2HVgwD http://t.co/bXalnEdy49\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.5384083390235901\n",
            "text:\n",
            "@Azimel 'Screaming Mad Scientist deceased after tumbling over heels and falling into sinkhole during investigation'\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.5279856324195862\n",
            "text:\n",
            "@nagel_ashley @Vicken52 @BasedLaRock @goonc1ty rip the world... its burning\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.5257343053817749\n",
            "text:\n",
            "@LegacyOfTheSith @SagaciousSaber @Lordofbetrayal Moved in a crescent formation small trails of dust left in their wake as they moved.\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.520277738571167\n",
            "text:\n",
            "WPRI 12 Eyewitness News Rhode Island set to modernize its voting equipment WPRI 12 EyewitnessÛ_ http://t.co/aP9JBrPmQg\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.5095019340515137\n",
            "text:\n",
            "Aftershock ã¢ (2010) Fullã¢ Streaming - YouTube http://t.co/vVE3UsesGf\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.5092296600341797\n",
            "text:\n",
            "Russian #ushanka #winter #military fur hat (xl61-62) with soviet badge LINK:\n",
            "http://t.co/74YFQxvAK0 http://t.co/KXrEHVt6hL\n",
            "\n",
            "Target : 0, Pred: 1.0, Prob:0.5043442845344543\n",
            "text:\n",
            "The Five Fatal Flaws in the Iran Deal https://t.co/ztfEAd8GId via @YouTube\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.49785667657852173\n",
            "text:\n",
            "@Dirk_NoMissSki yea but if someone faints why are they panicking?.. thats basic stuff ??\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.49502047896385193\n",
            "text:\n",
            "Back from Seattle Tacoma and Portland. Whirlwind! http://t.co/qwHINBni8e\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.49278557300567627\n",
            "text:\n",
            "#computers #gadgets Two giant cranes holding a bridge collapse into nearby homes http://t.co/UZIWgZRynY #slingnews\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.49255263805389404\n",
            "text:\n",
            "I moved to England five years ago today. What a whirlwind of time it has been! http://t.co/eaSlGeA1B7\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.4913441240787506\n",
            "text:\n",
            "China's Stock Market Crash: Are There Gems In The Rubble? http://t.co/BqBLWiw08g #ROIMentor #yycwalks\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.4635711908340454\n",
            "text:\n",
            "Medieval airplane hijacker testa: earnings the distinction divers: HtaRvrGLY\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.4567418098449707\n",
            "text:\n",
            "DireTube Information ÛÒ Egypt Cyprus and Greece agreed to fightåÊterrorism http://t.co/V6IjxCCD2I http://t.co/YSXhFWMGOD\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.44983839988708496\n",
            "text:\n",
            "US wont upgrade its infrastructure? http://t.co/NGEHhG9YGa' it a bad situation and its going to get ugly very quickly #USA #sustainability\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.4387258291244507\n",
            "text:\n",
            "A Dayton-area org tells me it was hit by a cyber attack: http://t.co/7LhKJz0IVO\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.41068413853645325\n",
            "text:\n",
            "133 N past  the 5 L lane is reopened. All other lanes are closed. All lanes are open on the 133 S. Trash truck fire cleanup. @KNX1070\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.4041580855846405\n",
            "text:\n",
            "Nearly had a heart attack just now; loud bang against window next to meÛ_turns out it was two birds flying into the glass.\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.3958092927932739\n",
            "text:\n",
            "#World #News Qld police wrap Billy Gordon investigation: QUEENSLAND Police have wrapped up their investigation...  http://t.co/msgnNDxOeK\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.39491426944732666\n",
            "text:\n",
            "When ur friend and u are talking about forest fires in a forest and he tells u to drop ur mix tape out there... #straightfire\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.3919870853424072\n",
            "text:\n",
            "I never knew about the relationship btwn Kansas City Hyatt bridge collapse &amp; AIA's COTE.   http://t.co/ThS9IqSWP3 via @HuffPostArts\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.3891797661781311\n",
            "text:\n",
            "@DavidJordan88 @Stephanenny Except we don't know who started the riot or if it even makes sense to credit any particular individuals...\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.38808155059814453\n",
            "text:\n",
            "There's a weird siren going off here...I hope Hunterston isn't in the process of blowing itself to smithereens...\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.387234628200531\n",
            "text:\n",
            "#ClimateChange Eyewitness to Extreme Weather: 11 Social Media Posts that Show Just How Crazy Things A... http://t.co/czpDn9oBiT #Anarchy\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.3847239315509796\n",
            "text:\n",
            "#Metepec #Mexico - ?NIGHT DISASTER?...E(Oficial) @ #NitClub #mÌ¼sica #mÌ¼sica http://t.co/WTfJF9jjzs\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.38206323981285095\n",
            "text:\n",
            "RT NotExplained: The only known image of infamous hijacker D.B. Cooper. http://t.co/JlzK2HdeTG\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.3810732364654541\n",
            "text:\n",
            "So this storm just came out of no where. .fuck me its cool\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.3761535882949829\n",
            "text:\n",
            "Breakfast links: Work from home: Derailed: An empty train derailed at Smithsonian this morning suspending ser... http://t.co/iD4QGqDnJQ\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.37122270464897156\n",
            "text:\n",
            "Oops: Bounty hunters try to raid Phoenix police chief's home: http://t.co/yPRJWMigHL -- A group of armed bounty... http://t.co/3RrKRCjYW7\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.3646329343318939\n",
            "text:\n",
            "@emmerdale can we have a public vote for the next annual village disaster?  i want an isis strike or a nuclear accident &amp; end this forever\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.3617401421070099\n",
            "text:\n",
            "@ColdMpress You up to commiting mass murder tonight?\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.3460535407066345\n",
            "text:\n",
            "Savings and sewing in Guatemala: Savings and sewing in Guatemala. When a natural disaster hit seamstress Elvia...  http://t.co/jdx9OX2kIk\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.3435417711734772\n",
            "text:\n",
            "Toddler drowned in bath after mum left room to fetch his pyjamas http://t.co/k9aSKtwXfL\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.33455222845077515\n",
            "text:\n",
            "Hollywood Movie About Trapped Miners Released in Chile: 'The 33' Hollywood movie about trapped miners starring... http://t.co/tyyfG4qQvM\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.32017287611961365\n",
            "text:\n",
            "Policyholders object to Clico rescue plan http://t.co/E4DvI9vUXZ http://t.co/JyCpf8iYhg\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.3073953092098236\n",
            "text:\n",
            "Crazy Mom Threw Teen Daughter a NUDE Twister Sex Party According To Her Friend50 =&gt;http://t.co/Hy5Pbe12TM http://t.co/c1nJpLi5oR\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.30522438883781433\n",
            "text:\n",
            "How is it one careless match can start a forest fire but it takes a whole box to start a campfire?\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.2612629532814026\n",
            "text:\n",
            "In Kalmikya Astrakhan Volgagrad and Dagestan there is already no food left for the locusts\n",
            "\n",
            "  http://t.co/79Fw9zWxtP via @TIMEWorld\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.2603350579738617\n",
            "text:\n",
            "Owner of Chicago-Area Gay Bar Admits to Arson Scheme http://t.co/ZPxE3fMYNG #LGBT\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.2523593604564667\n",
            "text:\n",
            "shit is hard to get over but sometimes the tragedy means it's over soulja..\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.24812757968902588\n",
            "text:\n",
            "#hot  Funtenna: hijacking computers to send data as sound waves [Black Hat 2015] http://t.co/cOMuiOk3mP #prebreak #best\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.2458740770816803\n",
            "text:\n",
            "Another fake hate crime Lesbians burn their own house down. What else Is new :http://t.co/66oBQmxImb\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.24200870096683502\n",
            "text:\n",
            "The date for the release of EP03 DESOLATION is set. Stay tuned for more info while we finalise the schedule. #alt #electro #rock #comingsoon\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.23014751076698303\n",
            "text:\n",
            "Would a paramedic really do that? Leave someone inside a building that's about to collapse/blow up? @HalloIkBenWill\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.22556006908416748\n",
            "text:\n",
            "Two hours to get to a client meeting. Whirlwind of emotions with this #tubestrike\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.22306475043296814\n",
            "text:\n",
            "First time getting into #gbbo2015 and physically gasped at the cake 'mudslide' incident already way too emotionally invested...\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.21822315454483032\n",
            "text:\n",
            "Plans by former First Lady and wife of ex-President Goodluck Jonathan Dame Patience Jonathan to hijack the All... http://t.co/HaShGQAFic\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.1962294727563858\n",
            "text:\n",
            "@camilacabello97 Internally and externally screaming\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.1931922435760498\n",
            "text:\n",
            "Sadly before she could save humanity Ursula drowned in the drool of a protoshoggoth but at least she sort of died doing what she loved.\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.1923598349094391\n",
            "text:\n",
            "annihilating quarterstaff of annihilation\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.18886810541152954\n",
            "text:\n",
            "How to prepare your #property for a #storm:\n",
            "\n",
            "http://t.co/KhYqQsi6My http://t.co/G6Vs3XEinb\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.18628449738025665\n",
            "text:\n",
            "Just came back from camping and returned with a new song which gets recorded tomorrow. Can't wait! #Desolation #TheConspiracyTheory #NewEP\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.18448221683502197\n",
            "text:\n",
            "when you don't know which way an ambulance is coming from &lt;&lt;\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.18259312212467194\n",
            "text:\n",
            "Body shops inundated with cars dented by hail... Good news insurance pays... Bad news :  you are stuck with deductible !\n",
            "#wcvb\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.18098455667495728\n",
            "text:\n",
            "Julian Knight - @SCVSupremeCourt dismisses mass murderer's attempt to increase prisoner pay. Challenged quantum of 5% increase 2013.\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.18058425188064575\n",
            "text:\n",
            "CDC has a pretty cool list of all bioterrorism agents :3\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.17405885457992554\n",
            "text:\n",
            "Can't believe more people in their mid 20's don't have high blood pressure. Life is stressful. #DecisionsOnDecisions\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.1733350157737732\n",
            "text:\n",
            "Stupid women nearly collided into me today after she came out of a junction not looking. Still kept coming towards me till I beep my horn\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.1731703132390976\n",
            "text:\n",
            "#download &amp; #watch Demolition Frog (2002) http://t.co/81nEizeknm #movie\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.17275020480155945\n",
            "text:\n",
            "Indeed!! I am fully aware of that battle! I support you in that fight!!  https://t.co/MctJnZX4H8\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.17246338725090027\n",
            "text:\n",
            "@dreamoforgonon @TeeEss not to hijack but as a bona fide cislady I can confirm this as true; incidental homosexuality =/= gay/bi for women.\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.17010685801506042\n",
            "text:\n",
            "World War II book LIGHTNING JOE An Autobiography by General J. Lawton Collins http://t.co/R4khEH7iaf http://t.co/qSZgJfUutu\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.1676202416419983\n",
            "text:\n",
            "suddenly it's off &amp; on gloomy &amp; thunder so loud it shakes the windows? Not ever on the Bay Area. Miss me w/that lol http://t.co/x4eCGGvnSN\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.1657072752714157\n",
            "text:\n",
            "@MichaelWestBiz standard damage control\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.15494674444198608\n",
            "text:\n",
            "When you go to a concert and someone screams in your ear... Does it look like I wanna loose my hearing anytime soon???\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.1503564566373825\n",
            "text:\n",
            "A quarter whirlwind. They don't see it coming.\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.14835862815380096\n",
            "text:\n",
            "@Habbo bring back games from the past. Snowstorm. Tic tac toe. Battleships. Fast food. Matchwood.\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.1193600744009018\n",
            "text:\n",
            "Leitchfield KY:\n",
            "\n",
            " Bella Edward &amp; Rosalie need rescue/adoption/local foster home(s)/sponsorships.\n",
            "\n",
            " Trapped &amp;... http://t.co/Ajay0sNPlg\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.11672412604093552\n",
            "text:\n",
            "So I pick myself off the ground and swam before I drowned. Hit the bottom so hard I bounced twice suffice this time around is different.\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.11602184921503067\n",
            "text:\n",
            "@GodOf_Mischief_ -of Loki's daggers she pulled it out and jammed it into Mina's thigh. When Mina screamed and grabbed at her leg sif-\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.1144515722990036\n",
            "text:\n",
            "The ol' meltdown victory for the Mets.\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.11191651225090027\n",
            "text:\n",
            "@cspanwj If 90BLKs&amp;8WHTs colluded 2 take WHT F @USAgov AUTH Hostage&amp;2 make her look BLK w/Bioterrorism&amp;use her lgl/org IDis ID still hers?\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.10821014642715454\n",
            "text:\n",
            "Yelp Bolsters Health Care Reviews With Investigative Journalism: Sick and injured patients at a local ER are t... http://t.co/E8aEGOFDY2\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.10678557306528091\n",
            "text:\n",
            "@SaintRobinho86 someone has to be at the bottom of every league. Tonight clearly demonstrated why the Lions are where they are - sunk!\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.1065485030412674\n",
            "text:\n",
            "Until my death I'll forever rep the Jets.\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.10461501032114029\n",
            "text:\n",
            "If I fall is men GOD @Praiz8 is d bomb well av always known dat since 2008 bigger u I pray sir\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.10175439715385437\n",
            "text:\n",
            "I Will Survive by Gloria Gaynor (with Oktaviana Devi) ÛÓ https://t.co/HUkJZ1wT36\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.1013348251581192\n",
            "text:\n",
            "I wanna set some shit on fire.\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.09887673705816269\n",
            "text:\n",
            "Rand Paul's Debate Strategy 'demolish Some other bad ideas out there or point out maybe that there are some em... http://t.co/qzdqRBr4Lh\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.09457100182771683\n",
            "text:\n",
            "Perspectives on the Grateful Dead: Critical Writings (Contributions to the Study http://t.co/fmu0fnuMxf http://t.co/AgGRyhVXKr\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.09369736164808273\n",
            "text:\n",
            "Petition | Heartless owner that whipped horse until it collapsed is told he can KEEP his animal! Act Now! http://t.co/87eFCBIczM\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.09234566986560822\n",
            "text:\n",
            "@Zak_Bagans this is Sabrina my dad rescued her from some dude who kept her in a cage. We've had her since I was 4 http://t.co/1k2PhQcuW8\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.08252666890621185\n",
            "text:\n",
            "New post from @darkreading http://t.co/8eIJDXApnp New SMB Relay Attack Steals User Credentials Over Internet\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.08042650669813156\n",
            "text:\n",
            "VICTORINOX SWISS ARMY DATE WOMEN'S RUBBER MOP WATCH 241487 http://t.co/yFy3nkkcoH http://t.co/KNEhVvOHVK\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.07898201048374176\n",
            "text:\n",
            "Next May I'll be free...from school from obligations like family.... Best of all that damn curfew...\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.07138810306787491\n",
            "text:\n",
            "@BoyInAHorsemask its a panda trapped in a dogs body\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.07125738263130188\n",
            "text:\n",
            "@reriellechan HE WAS THE LICH KING'S FIRST CASUALTY BLOCK ME BACK I HATE YOU! http://t.co/0Gidg9U45J\n",
            "\n",
            "Target : 1, Pred: 0.0, Prob:0.06967137008905411\n",
            "text:\n",
            "'The way you move is like a full on rainstorm and I'm a house of cards'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "  # Check the false negative (model predicted 1 when should've been 0)\n",
        "  for row in  most_wrong[:-10].itertuples():\n",
        "    _, text, target, pred, pred_prob = row\n",
        "    print(f\"Target : {target}, Pred: {pred}, Prob:{pred_prob}\")\n",
        "    print(f\"text:\\n{text}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruCX84G4mLJx"
      },
      "source": [
        "# Make predictions on the test dataset and visualizing them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnOJAcpon8ft"
      },
      "source": [
        "## Methode 1 : mrdbourg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8FyDpu0maWX",
        "outputId": "11cba706-c2c0-4a01-e196-2c9563fcbb57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 1s 9ms/step\n",
            "prob:[0.51997006 0.8752513  0.8278328  ... 0.9158135  0.5176442  0.6726021 ], pred : [1. 1. 1. ... 1. 1. 1.]\n",
            "Text:\n",
            "@swearyG It looks like the death star\n",
            "\n",
            "-----------\n",
            "102/102 [==============================] - 1s 9ms/step\n",
            "prob:[0.51997006 0.8752513  0.8278329  ... 0.9158135  0.5176442  0.6726021 ], pred : [1. 1. 1. ... 1. 1. 1.]\n",
            "Text:\n",
            "Please sign &amp; RT to save #SaltRiverWildHorses http://t.co/GB8ispiaRP http://t.co/Bx0l87iNc8\n",
            "\n",
            "-----------\n",
            "102/102 [==============================] - 1s 9ms/step\n",
            "prob:[0.51997006 0.8752513  0.8278329  ... 0.9158135  0.5176442  0.6726021 ], pred : [1. 1. 1. ... 1. 1. 1.]\n",
            "Text:\n",
            "Flood Advisory issued August 05 at 4:35PM EDT by NWS http://t.co/fuZ7y44P4I #WxKY\n",
            "\n",
            "-----------\n",
            "102/102 [==============================] - 1s 9ms/step\n",
            "prob:[0.51997006 0.87525123 0.8278329  ... 0.9158135  0.5176442  0.67260206], pred : [1. 1. 1. ... 1. 1. 1.]\n",
            "Text:\n",
            "Storm rolling into Hilton Head gonna be fun\n",
            "\n",
            "-----------\n",
            "102/102 [==============================] - 1s 9ms/step\n",
            "prob:[0.51997006 0.87525123 0.8278329  ... 0.9158135  0.5176442  0.6726021 ], pred : [1. 1. 1. ... 1. 1. 1.]\n",
            "Text:\n",
            "PKK Suicide Bombing Kills 2 Soldiers in Turkey http://t.co/dfanUDwSQ3\n",
            "\n",
            "-----------\n",
            "102/102 [==============================] - 1s 10ms/step\n",
            "prob:[0.51997006 0.87525123 0.8278329  ... 0.9158135  0.5176442  0.6726021 ], pred : [1. 1. 1. ... 1. 1. 1.]\n",
            "Text:\n",
            "@facilitydude shares how to handle the heat and keep your cool http://t.co/ekEd6BulsZ  #facilitiesmanagement\n",
            "\n",
            "-----------\n",
            "102/102 [==============================] - 1s 9ms/step\n",
            "prob:[0.51997006 0.8752513  0.8278328  ... 0.9158135  0.5176442  0.6726021 ], pred : [1. 1. 1. ... 1. 1. 1.]\n",
            "Text:\n",
            "I have stopped trying to figure out if THIS will be the misogyny/racism/religion-fueled shooting that will incite rioting.\n",
            "\n",
            "-----------\n",
            "102/102 [==============================] - 1s 9ms/step\n",
            "prob:[0.51997006 0.8752513  0.8278329  ... 0.9158135  0.5176442  0.6726021 ], pred : [1. 1. 1. ... 1. 1. 1.]\n",
            "Text:\n",
            "Uribe crushed it! #Mets\n",
            "\n",
            "-----------\n",
            "102/102 [==============================] - 1s 14ms/step\n",
            "prob:[0.51997006 0.8752513  0.8278329  ... 0.9158135  0.5176442  0.6726021 ], pred : [1. 1. 1. ... 1. 1. 1.]\n",
            "Text:\n",
            "Guess who's got a hilarious new piece on @RazedOnIt? @honeystaysuper! 51 Things You Should Never Say to a Mother Ever http://t.co/ikRHIb9x0a\n",
            "\n",
            "-----------\n",
            "102/102 [==============================] - 1s 9ms/step\n",
            "prob:[0.51997006 0.8752513  0.8278329  ... 0.9158135  0.5176443  0.6726021 ], pred : [1. 1. 1. ... 1. 1. 1.]\n",
            "Text:\n",
            "So many fires in NorCal they can't fight some of them. \n",
            "\n",
            "Pray for our firefighters air tanker pilots support crews &amp; evacuated people.\n",
            "\n",
            "-----------\n"
          ]
        }
      ],
      "source": [
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  model_6_pretrained_pred_probs_test = tf.squeeze(model_6_pretrained.predict(test_sentences))\n",
        "  model_6_pretrained_preds =tf.round(model_6_pretrained_pred_probs_test)\n",
        "  print(f\"prob:{model_6_pretrained_pred_probs_test}, pred : {model_6_pretrained_preds}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"-----------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9vxd209wrQ-",
        "outputId": "823e7173-7d51-4f9c-bb20-d5c130524391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TensorShape([762])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#test_sentences = test_df[\"text\"].to_numpy()\n",
        "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
        "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
        "model_6_pretrained_preds.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BxtPxTjoAMj"
      },
      "source": [
        "## Methode 2 : MrJuba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Hojh_rUdhuUu",
        "outputId": "923bbef3-2438-4e93-c18f-3d734a949bf6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1b184b06-2d1b-4098-85aa-7ef6e9a34e0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>pred</th>\n",
              "      <th>prob_preds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.519970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.875251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.827833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.933507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.967958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.800561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.967862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.915814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.517644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.672602</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b184b06-2d1b-4098-85aa-7ef6e9a34e0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b184b06-2d1b-4098-85aa-7ef6e9a34e0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b184b06-2d1b-4098-85aa-7ef6e9a34e0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               sentence  pred  prob_preds\n",
              "0                    Just happened a terrible car crash   1.0    0.519970\n",
              "1     Heard about #earthquake is different cities, s...   1.0    0.875251\n",
              "2     there is a forest fire at spot pond, geese are...   1.0    0.827833\n",
              "3              Apocalypse lighting. #Spokane #wildfires   1.0    0.933507\n",
              "4         Typhoon Soudelor kills 28 in China and Taiwan   1.0    0.967958\n",
              "...                                                 ...   ...         ...\n",
              "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...   1.0    0.800561\n",
              "3259  Storm in RI worse than last hurricane. My city...   1.0    0.967862\n",
              "3260  Green Line derailment in Chicago http://t.co/U...   1.0    0.915814\n",
              "3261  MEG issues Hazardous Weather Outlook (HWO) htt...   1.0    0.517644\n",
              "3262  #CityofCalgary has activated its Municipal Eme...   1.0    0.672602\n",
              "\n",
              "[3263 rows x 3 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_6_pretrained_preds\n",
        "test_df_pred =  pd.DataFrame({\"sentence\": test_sentences,\n",
        "                              \"pred\": model_6_pretrained_preds,\n",
        "                              \"prob_preds\": tf.squeeze(model_6_pretrained_pred_probs_test)})\n",
        "test_df_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0X-KuY-kmi-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMoBNnrdoLhC"
      },
      "source": [
        "## Your challenge.. predicting on Tweets from the wild\n",
        "\n",
        "Go to your favourite Twitter accound and copy on of their layers Tweets.\n",
        "\n",
        "Then pass that Tweet through our trained model.\n",
        "\n",
        "Is that Tweet a disaster or not disaster (according to the model)? Is the model right or wrong ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5Yd1YCM9QBo"
      },
      "outputs": [],
      "source": [
        "# Let's make a function to measure the time of prediction\n",
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make predictions on samples\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter() # get start time\n",
        "  model.predict(samples) # make predictions\n",
        "  end_time = time.perf_counter() # get finish time\n",
        "  total_time = end_time - start_time # calculate how long predictions took to make\n",
        "  time_per_pred = total_time/len(samples)\n",
        "  return total_time, time_per_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n9N3JRL9P-p",
        "outputId": "2da709cd-e950-4ed9-f534-6ee562477b57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 9ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.2785869669996828, 0.0003655996942253055)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate TF Hub Sentence Encoder time per pred\n",
        "model_6_time_total_pred, model_6_time_per_pred = pred_timer(model=model_6_pretrained,\n",
        "                                                            samples=val_sentences)\n",
        "model_6_time_total_pred, model_6_time_per_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RchdiVrB9P7k",
        "outputId": "fb4c386f-9493-47a8-d30c-af455fcc45c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.016446343999632518, 2.1583128608441625e-05)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate our baseline model times per pred\n",
        "baseline_time_total_pred, baseline_time_per_pred = pred_timer(model=model_0, samples=val_sentences)\n",
        "baseline_time_total_pred, baseline_time_per_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX0awWQY_-ha",
        "outputId": "68b3f56f-6f9c-4854-b494-309652c36f52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 81.62729658792651,\n",
              " 'precision': 0.818446310697231,\n",
              " 'recall': 0.8162729658792651,\n",
              " 'f1': 0.8148082644367335}"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# calculate results of model\n",
        "model_6_pretrained_results = calculate_results(y_true = val_labels, y_pred = model_6_pretrained_preds)\n",
        "model_6_pretrained_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CErcTqxEmsK5"
      },
      "source": [
        "### Ideal speed / performance trade off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "AIPWQBnV_yfK",
        "outputId": "5aea9237-4406-4f5d-f84b-39292ef36b00"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_pretrained_results[\"f1\"], label=\"tf_hub_sentence_encoder\")\n",
        "plt.legend()\n",
        "plt.title(\"F1-score versus time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"F1-score\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHcIr7cC9P4l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFHB6ykA_9hG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeYVy56m9P1k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohAJX-3AolUe"
      },
      "outputs": [],
      "source": [
        "test_twitter_sentence = \"kill one or all\"\n",
        "test_twitter_list = [test_twitter_sentence]\n",
        "test_twitter_array = np.array(test_twitter_list, dtype=object)\n",
        "test_twitter_df = pd.DataFrame(test_twitter_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfV-X324p6ZN",
        "outputId": "cb3e7442-4300-4e4d-8f87-d8ea720e2900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "sentence                                  [kill one or all]\n",
              "pred                tf.Tensor(0.0, shape=(), dtype=float32)\n",
              "prob_preds    tf.Tensor(0.1955892, shape=(), dtype=float32)\n",
              "dtype: object"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_6_pretrained_pred_probs_test = model_6_pretrained.predict(test_twitter_array)\n",
        "model_6_pretrained_preds_test = tf.squeeze(tf.round(model_6_pretrained_pred_probs_test))\n",
        "\n",
        "# test_df_pred =  pd.DataFrame({\"sentence\": test_twitter_list,\n",
        "#                               \"pred\": tf.squeeze(model_6_pretrained_preds_test),\n",
        "#                               \"prob_preds\": tf.squeeze(model_6_pretrained_pred_probs_test)})\n",
        "\n",
        "test_df_pred =  pd.Series({\"sentence\": test_twitter_array,\n",
        "                           \"pred\": tf.squeeze(model_6_pretrained_preds_test),\n",
        "                           \"prob_preds\": tf.squeeze(model_6_pretrained_pred_probs_test)})\n",
        "test_df_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-lcVaDWqG11"
      },
      "outputs": [],
      "source": [
        "test_twitter_df = pd.DataFrame(test_twitter_array, columns=['sentence'])\n",
        "pred = tf.squeeze(model_6_pretrained_preds_test).numpy()\n",
        "prob_preds = tf.squeeze(model_6_pretrained_pred_probs_test).numpy()\n",
        "test_df_pred =  pd.DataFrame({\"sentence\": test_twitter_df['sentence'],\n",
        "                              \"pred\": pred,\n",
        "                              \"prob_preds\": prob_preds},\n",
        "                             index= test_twitter_df.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "OHb-8-Kd8sxd",
        "outputId": "1dca67df-ce49-4dc4-af88-da8ad1dd7ea6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3cf745fb-3544-4db7-9493-e629bddd6f59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>pred</th>\n",
              "      <th>prob_preds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kill one or all</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.195589</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cf745fb-3544-4db7-9493-e629bddd6f59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cf745fb-3544-4db7-9493-e629bddd6f59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cf745fb-3544-4db7-9493-e629bddd6f59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          sentence  pred  prob_preds\n",
              "0  kill one or all   0.0    0.195589"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKVzhwG68uFI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "tmdTOX7bGUZ6"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}