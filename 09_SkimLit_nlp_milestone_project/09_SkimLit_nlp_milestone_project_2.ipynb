{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f45d0e6",
   "metadata": {},
   "source": [
    "# Milestone Poject 2 : skimLit\n",
    "\n",
    "The purpose of this notebook is to build an NLP model to make reading medical abstracts easier.\n",
    "\n",
    "The paper we're replicating (the source of the dataset that we'll be using) is available here : https://arxiv.org/abs/1710.06071\n",
    "        \n",
    "And reading through the paper above, we see that the model architecture that they use to achieve their best results is available : https://arxiv.org/abs/1612.05251\n",
    "        \n",
    "*Resource :* If you want to find the ground truth for this notebook(with lots of diagrams and text annotation) see the Github: https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54a03fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb  1 22:12:53 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 517.00       Driver Version: 517.00       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   58C    P8     3W /  N/A |      0MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3640      C   ...\\app-1.0.9010\\Discord.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Confirm acces to GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0be4c13",
   "metadata": {},
   "source": [
    "## Get data\n",
    "\n",
    "Since we'll be replicating the paper above (PubMed 200K RCT)? let's download the dataset they used,\n",
    "We can do so from the authors GitHub : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6e4a383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'pubmed-rct' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct\n",
    "# Check what files are in the PubMed_20K dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bca12cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le volume dans le lecteur C n'a pas de nom.\n",
      " Le num‚ro de s‚rie du volume est 1A6B-64E7\n",
      "\n",
      " R‚pertoire de C:\\Users\\wjub\\01workspace\\TensorFlow Developer Certificate ZTM\\partie_2\\TensorFlow_Developer_Certificate_ZTM\\09_SkimLit_nlp_milestone_project\\pubmed-rct\n",
      "\n",
      "30/01/2023  08:23    <DIR>          .\n",
      "01/02/2023  22:12    <DIR>          ..\n",
      "30/01/2023  08:23    <DIR>          PubMed_200k_RCT\n",
      "30/01/2023  08:23    <DIR>          PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
      "30/01/2023  08:23    <DIR>          PubMed_20k_RCT\n",
      "30/01/2023  08:23    <DIR>          PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
      "30/01/2023  08:23             2ÿ403 README.md\n",
      "               1 fichier(s)            2ÿ403 octets\n",
      "               6 R‚p(s)  430ÿ530ÿ322ÿ432 octets libres\n"
     ]
    }
   ],
   "source": [
    "ls pubmed-rct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7df42271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le volume dans le lecteur C n'a pas de nom.\n",
      " Le num‚ro de s‚rie du volume est 1A6B-64E7\n",
      "\n",
      " R‚pertoire de C:\\Users\\wjub\\01workspace\\TensorFlow Developer Certificate ZTM\\partie_2\\TensorFlow_Developer_Certificate_ZTM\\09_SkimLit_nlp_milestone_project\\pubmed-rct\\PubMed_20k_RCT\n",
      "\n",
      "30/01/2023  08:23    <DIR>          .\n",
      "30/01/2023  08:23    <DIR>          ..\n",
      "30/01/2023  08:23         4ÿ962ÿ110 dev.txt\n",
      "30/01/2023  08:23         4ÿ924ÿ980 test.txt\n",
      "30/01/2023  08:23        29ÿ594ÿ141 train.txt\n",
      "               3 fichier(s)       39ÿ481ÿ231 octets\n",
      "               2 R‚p(s)  430ÿ530ÿ338ÿ816 octets libres\n"
     ]
    }
   ],
   "source": [
    "ls pubmed-rct\\PubMed_20k_RCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69a4f183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le volume dans le lecteur C n'a pas de nom.\n",
      " Le num‚ro de s‚rie du volume est 1A6B-64E7\n",
      "\n",
      " R‚pertoire de C:\\Users\\wjub\\01workspace\\TensorFlow Developer Certificate ZTM\\partie_2\\TensorFlow_Developer_Certificate_ZTM\\09_SkimLit_nlp_milestone_project\\pubmed-rct\\PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
      "\n",
      "30/01/2023  08:23    <DIR>          .\n",
      "30/01/2023  08:23    <DIR>          ..\n",
      "30/01/2023  08:23         4ÿ880ÿ409 dev.txt\n",
      "30/01/2023  08:23         4ÿ846ÿ504 test.txt\n",
      "30/01/2023  08:23        29ÿ118ÿ832 train.txt\n",
      "               3 fichier(s)       38ÿ845ÿ745 octets\n",
      "               2 R‚p(s)  430ÿ530ÿ338ÿ816 octets libres\n"
     ]
    }
   ],
   "source": [
    "ls pubmed-rct\\PubMed_20k_RCT_numbers_replaced_with_at_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de21e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start our experiments using the 20k dataset with numbers replaced by \"#\" sign\n",
    "data_dir = \"pubmed-rct\\PubMed_20k_RCT_numbers_replaced_with_at_sign\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cd8928d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pubmed-rct\\\\PubMed_20k_RCT_numbers_replaced_with_at_sign\\\\dev.txt',\n",
       " 'pubmed-rct\\\\PubMed_20k_RCT_numbers_replaced_with_at_sign\\\\test.txt',\n",
       " 'pubmed-rct\\\\PubMed_20k_RCT_numbers_replaced_with_at_sign\\\\train.txt']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all of the filenames in the target directory\n",
    "import os\n",
    "filenames= [data_dir + filename for filename in os.listdir(data_dir)]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d146a0",
   "metadata": {},
   "source": [
    "## Preprocess data \n",
    "\n",
    "Now we've got some text data, it's time to become one with it.\n",
    "\n",
    "And one of the best ways to become one with data is to...\n",
    "\n",
    "> Visualize, visualize, vizualize\n",
    "\n",
    "So with that in mind, let's write a function to read in all of the lines of a target text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4055be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to read lines of a document\n",
    "def get_lines(filename):\n",
    "    \"\"\"\n",
    "    Reads filename (a text filename) and returns the line of text as list.\n",
    "    \n",
    "    Args:\n",
    "    \tfilename: a string containing the target filepath.\n",
    "    Returns:\n",
    "    \tA list of strings with one string with one string per line from the target filename.  \n",
    "    \"\"\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        return f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33f204b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['###24293578\\n',\n",
       " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
       " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
       " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
       " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
       " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
       " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
       " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
       " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
       " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
       " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
       " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
       " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
       " '\\n',\n",
       " '###24854809\\n',\n",
       " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
       " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
       " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
       " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
       " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n',\n",
       " 'METHODS\\tAttentional biases for high caloric foods were measured by eye tracking during a visual probe task with pictorial food and neutral stimuli .\\n',\n",
       " 'METHODS\\tSelf-reported emotional eating was assessed with the Dutch Eating Behavior Questionnaire ( DEBQ ) and ad libitum food intake was tested by a disguised food offer .\\n',\n",
       " 'RESULTS\\tHierarchical multivariate regression modeling showed that self-reported emotional eating did not account for changes in attention allocation for food or food intake in either condition .\\n',\n",
       " 'RESULTS\\tYet , attention maintenance on food cues was significantly related to increased intake specifically in the neutral condition , but not in the sad mood condition .\\n',\n",
       " 'CONCLUSIONS\\tThe current findings show that self-reported emotional eating ( based on the DEBQ ) might not validly predict who overeats when sad , at least not in a laboratory setting with healthy women .\\n',\n",
       " 'CONCLUSIONS\\tResults further suggest that attention maintenance on food relates to eating motivation when in a neutral affective state , and might therefore be a cognitive mechanism contributing to increased food intake in general , but maybe not during sad mood .\\n',\n",
       " '\\n',\n",
       " '###25165090\\n',\n",
       " 'BACKGROUND\\tAlthough working smoke alarms halve deaths in residential fires , many households do not keep alarms operational .\\n',\n",
       " 'BACKGROUND\\tWe tested whether theory-based education increases alarm operability .\\n']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in the training lines\n",
    "train_lines = get_lines(data_dir+\"train.txt\")\n",
    "train_lines[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d7dd655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210040"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e4ada0",
   "metadata": {},
   "source": [
    "Let's think about how we want our data to look...\n",
    "\n",
    "How I think our data would be best represented.\n",
    "\n",
    "```\n",
    "[{'line_number':0,\n",
    "\t'target': 'BACKGROUND'?\n",
    "    'text': \"Emotional eating is associated with overeating and the development of obesity\",\n",
    "    'total_lines:11'}\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421b1678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f8465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb66636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83427034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86a862c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b9f5af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines_data(filename):\n",
    "    # Create an empty list to store processed lines\n",
    "    result = []\n",
    "    \n",
    "    # Open the file in read mode\n",
    "    with open(filename, \"r\") as f:\n",
    "        # Read all lines of the file\n",
    "        lines = f.readlines()\n",
    "        # Initialize a counter to keep track of total lines\n",
    "        total_lines = 0\n",
    "        # Iterate over each line in the file\n",
    "        for line_number, line in enumerate(lines):\n",
    "            # Check if the line starts with '###'\n",
    "            if line.startswith(\"###\"):\n",
    "                # If yes, reset the total_lines counter\n",
    "                total_lines = 0\n",
    "            else:\n",
    "                # If not, increment the total_lines counter\n",
    "                total_lines += 1\n",
    "            # Split the line using '\\t' as a separator\n",
    "            split_line = line.split(\"\\t\")\n",
    "            # Check if the split line has at least two parts\n",
    "            if len(split_line) >= 2:\n",
    "                # Extract the target and text from the split line\n",
    "                target = split_line[0]\n",
    "                text = split_line[1].replace(\"\\n\", \"\").strip()\n",
    "                # Add the processed line as a dictionary to the result list\n",
    "                result.append({\n",
    "                    'line_number': line_number-1,\n",
    "                    'target': target,\n",
    "                    'text': text,\n",
    "                    'total_lines': total_lines\n",
    "                })\n",
    "    # Return the list of processed lines\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27353c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to read the lines of a document\n",
    "def get_lines(filename):\n",
    "  \"\"\"\n",
    "  Reads filename (a text file) and returns the lines of text as a list.\n",
    "  \n",
    "  Args:\n",
    "      filename: a string containing the target filepath to read.\n",
    "  \n",
    "  Returns:\n",
    "      A list of strings with one string per line from the target filename.\n",
    "      For example:\n",
    "      [\"this is the first line of filename\",\n",
    "       \"this is the second line of filename\",\n",
    "       \"...\"]\n",
    "  \"\"\"\n",
    "  with open(filename, \"r\") as f:\n",
    "    return f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b037f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0fb2f94c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'line_number': 0,\n",
       "  'target': 'OBJECTIVE',\n",
       "  'text': 'To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .',\n",
       "  'total_lines': 1},\n",
       " {'line_number': 1,\n",
       "  'target': 'METHODS',\n",
       "  'text': 'A total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       "  'total_lines': 2},\n",
       " {'line_number': 2,\n",
       "  'target': 'METHODS',\n",
       "  'text': 'Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       "  'total_lines': 3},\n",
       " {'line_number': 3,\n",
       "  'target': 'METHODS',\n",
       "  'text': 'Pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       "  'total_lines': 4},\n",
       " {'line_number': 4,\n",
       "  'target': 'METHODS',\n",
       "  'text': 'Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .',\n",
       "  'total_lines': 5},\n",
       " {'line_number': 5,\n",
       "  'target': 'METHODS',\n",
       "  'text': 'Serum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .',\n",
       "  'total_lines': 6},\n",
       " {'line_number': 6,\n",
       "  'target': 'RESULTS',\n",
       "  'text': 'There was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .',\n",
       "  'total_lines': 7},\n",
       " {'line_number': 7,\n",
       "  'target': 'RESULTS',\n",
       "  'text': 'The mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       "  'total_lines': 8},\n",
       " {'line_number': 8,\n",
       "  'target': 'RESULTS',\n",
       "  'text': 'Further , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .',\n",
       "  'total_lines': 9},\n",
       " {'line_number': 9,\n",
       "  'target': 'RESULTS',\n",
       "  'text': 'These differences remained significant at @ weeks .',\n",
       "  'total_lines': 10},\n",
       " {'line_number': 10,\n",
       "  'target': 'RESULTS',\n",
       "  'text': 'The Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
       "  'total_lines': 11},\n",
       " {'line_number': 11,\n",
       "  'target': 'CONCLUSIONS',\n",
       "  'text': 'Low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .',\n",
       "  'total_lines': 12},\n",
       " {'line_number': 14,\n",
       "  'target': 'BACKGROUND',\n",
       "  'text': 'Emotional eating is associated with overeating and the development of obesity .',\n",
       "  'total_lines': 1},\n",
       " {'line_number': 15,\n",
       "  'target': 'BACKGROUND',\n",
       "  'text': 'Yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
       "  'total_lines': 2},\n",
       " {'line_number': 16,\n",
       "  'target': 'OBJECTIVE',\n",
       "  'text': 'The aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .',\n",
       "  'total_lines': 3},\n",
       " {'line_number': 17,\n",
       "  'target': 'OBJECTIVE',\n",
       "  'text': 'It was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .',\n",
       "  'total_lines': 4},\n",
       " {'line_number': 18,\n",
       "  'target': 'METHODS',\n",
       "  'text': 'Participants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .',\n",
       "  'total_lines': 5},\n",
       " {'line_number': 19,\n",
       "  'target': 'METHODS',\n",
       "  'text': 'Attentional biases for high caloric foods were measured by eye tracking during a visual probe task with pictorial food and neutral stimuli .',\n",
       "  'total_lines': 6},\n",
       " {'line_number': 20,\n",
       "  'target': 'METHODS',\n",
       "  'text': 'Self-reported emotional eating was assessed with the Dutch Eating Behavior Questionnaire ( DEBQ ) and ad libitum food intake was tested by a disguised food offer .',\n",
       "  'total_lines': 7},\n",
       " {'line_number': 21,\n",
       "  'target': 'RESULTS',\n",
       "  'text': 'Hierarchical multivariate regression modeling showed that self-reported emotional eating did not account for changes in attention allocation for food or food intake in either condition .',\n",
       "  'total_lines': 8}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = data_dir+\"train.txt\"\n",
    "target = \"BACKGROUND\"\n",
    "get_lines_data(filename)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7b785074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_with_line_numbers(filename):\n",
    "  \"\"\"Returns a list of dictionaries of abstract line data.\n",
    "\n",
    "  Takes in filename, reads its contents and sorts through each line,\n",
    "  extracting things like the target label, the text of the sentence,\n",
    "  how many sentences are in the current abstract and what sentence number\n",
    "  the target line is.\n",
    "\n",
    "  Args:\n",
    "      filename: a string of the target text file to read and extract line data\n",
    "      from.\n",
    "\n",
    "  Returns:\n",
    "      A list of dictionaries each containing a line from an abstract,\n",
    "      the lines label, the lines position in the abstract and the total number\n",
    "      of lines in the abstract where the line is from. For example:\n",
    "\n",
    "      [{\"target\": 'CONCLUSION',\n",
    "        \"text\": The study couldn't have gone better, turns out people are kinder than you think\",\n",
    "        \"line_number\": 8,\n",
    "        \"total_lines\": 8}]\n",
    "  \"\"\"\n",
    "  input_lines = get_lines(filename) # get all lines from filename\n",
    "  abstract_lines = \"\" # create an empty abstract\n",
    "  abstract_samples = [] # create an empty list of abstracts\n",
    "  \n",
    "  # Loop through each line in target file\n",
    "  for line in input_lines:\n",
    "    if line.startswith(\"###\"): # check to see if line is an ID line\n",
    "      abstract_id = line\n",
    "      abstract_lines = \"\" # reset abstract string\n",
    "    elif line.isspace(): # check to see if line is a new line\n",
    "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
    "\n",
    "      # Iterate through each line in abstract and count them at the same time\n",
    "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
    "        line_data = {} # create empty dict to store data from line\n",
    "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
    "        line_data[\"target\"] = target_text_split[0] # get target label\n",
    "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
    "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
    "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
    "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
    "    \n",
    "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
    "      abstract_lines += line\n",
    "  \n",
    "  return abstract_samples\n",
    "\n",
    "def preprocess_text_with_line_numbers(filename):\n",
    "    \"\"\"\n",
    "    Returns a list of dictionaries of abstract line data.\n",
    "    \n",
    "    Take in filename, read it contents and sorts through each line, extracting things like the \n",
    "    target label, the text of the sentences, how many sentences are in the current abstract and \n",
    "    what sentence number the target line is.\n",
    "    \"\"\"\n",
    "    input_lines = get_lines(filename) # get all lines from filename\n",
    "    abstract_lines = \"\" # create an empty abstract\n",
    "    # Loop through each line in the target file\n",
    "    abstract_samples = []\n",
    "    for line in input_lines:\n",
    "        if line.startswith(\"###\"): # check to see if the line is an ID line\n",
    "            abstract_id  = line\n",
    "            abstract_lines = \"\" # reset the abstract string if the line is an ID line\n",
    "\n",
    "        elif line.isspace():\n",
    "            abstract_line_split = abstract_lines.splitlines()\n",
    "            for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
    "                line_data = {} # Create an empty dictionnary\n",
    "                target_text_split = abstract_line.split(\"\\t\")   \n",
    "                line_data[\"target\"] = target_text_split[0]\n",
    "                line_data[\"text\"] = target_text_split[1].lower()\n",
    "                line_data[\"line_number\"] = abstract_line_number  \n",
    "                line_data[\"total_lines\"] = len(abstract_line_split) - 1\n",
    "                abstract_samples.append(line_data) # add line data to abstract samples list\n",
    "        else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
    "            abstract_lines += line\n",
    "    return abstract_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "87dc5acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "180040 30212 30135\n"
     ]
    }
   ],
   "source": [
    "# Get data from file and preprocess it \n",
    "%time\n",
    "train_samples = preprocess_text_with_line_numbers(data_dir+\"train.txt\")\n",
    "val_samples = preprocess_text_with_line_numbers(data_dir+\"dev.txt\") # dev is another name for validation dataset\n",
    "test_samples = preprocess_text_with_line_numbers(data_dir+\"test.txt\")\n",
    "print(len(train_samples), len(val_samples), len(test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd680aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
