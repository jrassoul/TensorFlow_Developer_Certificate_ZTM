{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jy273MxWs9JpRUT6kp--Lj6r41m2765_",
      "authorship_tag": "ABX9TyMmkusiV5aBC5QV7nH80625"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Milestone Poject 2 : skimLit\n",
        "\n",
        "The purpose of this notebook is to build an NLP model to make reading medical abstracts easier.\n",
        "\n",
        "The paper we're replicating (the source of the dataset that we'll be using) is available here : https://arxiv.org/abs/1710.06071\n",
        "        \n",
        "And reading through the paper above, we see that the model architecture that they use to achieve their best results is available : https://arxiv.org/abs/1612.05251\n",
        "        \n",
        "*Resource :* If you want to find the ground truth for this notebook(with lots of diagrams and text annotation) see the Github: https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb\n",
        "\n"
      ],
      "metadata": {
        "id": "rUvkCiyW5bnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dependencies\n",
        "import sys\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "# sys.path.append(r\"C:\\Users/wjub/01workspace/TensorFlow Developer Certificate ZTM\")\n",
        "sys.path.append(r\"/content/drive/MyDrive/TensorFlow_Developer_Certificate_ZTM/\")\n",
        "\n",
        "import helper_functions\n",
        "from helper_functions import calculate_results\n",
        "import random"
      ],
      "metadata": {
        "id": "Huinz6QO5YsF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gJAyIoHr8eaw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30a66893-81ba-48b9-b269-4233d799eb44"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm acces to GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR3rMGRe5rS-",
        "outputId": "5dc09f00-8403-48af-c61f-95bfcf9dde5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Feb 13 20:13:37 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P0    26W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get data\n",
        "\n",
        "Since we'll be replicating the paper above (PubMed 200K RCT)? let's download the dataset they used,\n",
        "We can do so from the authors GitHub : "
      ],
      "metadata": {
        "id": "iCLEnoWv5uu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "# Check what files are in the PubMed_20K dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guziDrsI5sst",
        "outputId": "1475a73b-4384-480a-c391-4bb3262b82a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 33 (delta 5), reused 5 (delta 5), pack-reused 25\u001b[K\n",
            "Unpacking objects: 100% (33/33), 177.08 MiB | 5.92 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls pubmed-rct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTazp-225wtt",
        "outputId": "f9952d0f-2e51-4cbb-ca6d-7dbb35778a5b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mPubMed_200k_RCT\u001b[0m/\n",
            "\u001b[01;34mPubMed_200k_RCT_numbers_replaced_with_at_sign\u001b[0m/\n",
            "\u001b[01;34mPubMed_20k_RCT\u001b[0m/\n",
            "\u001b[01;34mPubMed_20k_RCT_numbers_replaced_with_at_sign\u001b[0m/\n",
            "README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls pubmed-rct/PubMed_20k_RCT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCB3YsJl5xmN",
        "outputId": "726735fe-a292-4f8e-82b0-7aa0f9352f11"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start our experiments using the 20k dataset with numbers replaced by \"#\" sign\n",
        "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "metadata": {
        "id": "jyIwh_pR509b"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check all of the filenames in the target directory\n",
        "import os\n",
        "filenames= [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMitT4s0506m",
        "outputId": "88788426-4ce6-4f17-c0e5-af1b3c7df78d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess data \n",
        "\n",
        "Now we've got some text data, it's time to become one with it.\n",
        "\n",
        "And one of the best ways to become one with data is to...\n",
        "\n",
        "> Visualize, visualize, vizualize\n",
        "\n",
        "So with that in mind, let's write a function to read in all of the lines of a target text file."
      ],
      "metadata": {
        "id": "0BJlNq8a6IaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to read lines of a document\n",
        "def get_lines(filename):\n",
        "    \"\"\"\n",
        "    Reads filename (a text filename) and returns the line of text as list.\n",
        "    \n",
        "    Args:\n",
        "    \tfilename: a string containing the target filepath.\n",
        "    Returns:\n",
        "    \tA list of strings with one string with one string per line from the target filename.  \n",
        "    \"\"\"\n",
        "    with open(filename, \"r\") as f:\n",
        "        return f.readlines()"
      ],
      "metadata": {
        "id": "yvmBmYif504Q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's read in the training lines\n",
        "train_lines = get_lines(data_dir+\"train.txt\")\n",
        "train_lines[:30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR4eXd0g501x",
        "outputId": "da59bb3a-d763-42fe-b682-e98d17928026"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n',\n",
              " 'METHODS\\tAttentional biases for high caloric foods were measured by eye tracking during a visual probe task with pictorial food and neutral stimuli .\\n',\n",
              " 'METHODS\\tSelf-reported emotional eating was assessed with the Dutch Eating Behavior Questionnaire ( DEBQ ) and ad libitum food intake was tested by a disguised food offer .\\n',\n",
              " 'RESULTS\\tHierarchical multivariate regression modeling showed that self-reported emotional eating did not account for changes in attention allocation for food or food intake in either condition .\\n',\n",
              " 'RESULTS\\tYet , attention maintenance on food cues was significantly related to increased intake specifically in the neutral condition , but not in the sad mood condition .\\n',\n",
              " 'CONCLUSIONS\\tThe current findings show that self-reported emotional eating ( based on the DEBQ ) might not validly predict who overeats when sad , at least not in a laboratory setting with healthy women .\\n',\n",
              " 'CONCLUSIONS\\tResults further suggest that attention maintenance on food relates to eating motivation when in a neutral affective state , and might therefore be a cognitive mechanism contributing to increased food intake in general , but maybe not during sad mood .\\n',\n",
              " '\\n',\n",
              " '###25165090\\n',\n",
              " 'BACKGROUND\\tAlthough working smoke alarms halve deaths in residential fires , many households do not keep alarms operational .\\n',\n",
              " 'BACKGROUND\\tWe tested whether theory-based education increases alarm operability .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ6kb8tq50zO",
        "outputId": "14cb569d-00ff-4c74-fffb-df9427d41d25"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210040"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import preprocess_text_with_line_numbers"
      ],
      "metadata": {
        "id": "KsQ-vKvr50wv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YaXmYMny-_dJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data from file and preprocess it \n",
        "%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir+\"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir+\"dev.txt\") # dev is another name for validation dataset\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir+\"test.txt\")\n",
        "print(len(train_samples), len(val_samples), len(test_samples))"
      ],
      "metadata": {
        "id": "lzOmnM4H50uo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d097db-0146-454d-f27e-d5493ff2843c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.2 µs\n",
            "180040 30212 30135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our data is the frormat of a list of ditionaries, how about we turn it into dataframe to futher visualize it?"
      ],
      "metadata": {
        "id": "Pjq2FuPg7lXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the first abstract_line\n",
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(train_samples)\n",
        "test_df = pd.DataFrame(train_samples)\n",
        "#train_df[\"target\"] = numeric_labels\n",
        "train_df"
      ],
      "metadata": {
        "id": "DMLtYxZc50ry",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c1fa2303-1c7a-461c-e5d3-a609897d77f8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             target                                               text  \\\n",
              "0         OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
              "1           METHODS  a total of @ patients with primary knee oa wer...   \n",
              "2           METHODS  outcome measures included pain reduction and i...   \n",
              "3           METHODS  pain was assessed using the visual analog pain...   \n",
              "4           METHODS  secondary outcome measures included the wester...   \n",
              "...             ...                                                ...   \n",
              "180035      RESULTS  for the absolute change in percent atheroma vo...   \n",
              "180036      RESULTS  for pav , a significantly greater percentage o...   \n",
              "180037      RESULTS  both strategies had acceptable side effect pro...   \n",
              "180038  CONCLUSIONS  compared with standard statin monotherapy , th...   \n",
              "180039  CONCLUSIONS  ( plaque regression with cholesterol absorptio...   \n",
              "\n",
              "        line_number  total_lines  \n",
              "0                 0           11  \n",
              "1                 1           11  \n",
              "2                 2           11  \n",
              "3                 3           11  \n",
              "4                 4           11  \n",
              "...             ...          ...  \n",
              "180035            7           11  \n",
              "180036            8           11  \n",
              "180037            9           11  \n",
              "180038           10           11  \n",
              "180039           11           11  \n",
              "\n",
              "[180040 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84e4164e-566c-469e-9008-522f8a26b39d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180035</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>for the absolute change in percent atheroma vo...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180036</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>for pav , a significantly greater percentage o...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180037</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>both strategies had acceptable side effect pro...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180038</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>compared with standard statin monotherapy , th...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180039</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>( plaque regression with cholesterol absorptio...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>180040 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84e4164e-566c-469e-9008-522f8a26b39d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-84e4164e-566c-469e-9008-522f8a26b39d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-84e4164e-566c-469e-9008-522f8a26b39d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of labels in training data\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "id": "vi6muObV50pO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffccea4f-1cec-4f6b-a5c2-71c3aea64cbf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check length of different lines\n",
        "train_df.total_lines.plot.hist()"
      ],
      "metadata": {
        "id": "ScSjxH0e50m5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "d1d51445-3c81-4fa2-e8ee-1111f6f59299"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcfcc29f580>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get lists of senteces"
      ],
      "metadata": {
        "id": "IlHBzkfQ7sQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert abstract text lines into lists\n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)\n"
      ],
      "metadata": {
        "id": "A7nD5ZKl7ol-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfbbb4be-4c5f-4b83-ee7d-ba74e5bac094"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 180040, 180040)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the 10 lines o ftraining sentences\n",
        "train_sentences[:10]"
      ],
      "metadata": {
        "id": "rNW1oG9-50ko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fdcd495-cbda-45e2-844e-380dea101cab"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make numeric labels (ML models require numeric labels)"
      ],
      "metadata": {
        "id": "ZE-626A47wIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False) # we want non-sparse matrix\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1,1))\n",
        "val_labels_one_hot = one_hot_encoder.fit_transform(val_df[\"target\"].to_numpy().reshape(-1,1))\n",
        "test_labels_one_hot = one_hot_encoder.fit_transform(test_df[\"target\"].to_numpy().reshape(-1,1))\n",
        "\n",
        "# check what one hot encoded labels look like\n",
        "train_labels_one_hot"
      ],
      "metadata": {
        "id": "Toa-UNmW7uVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ad69f6-06fa-46a7-d90d-76d3312f64dc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.constant(train_labels_one_hot)"
      ],
      "metadata": {
        "id": "dbacq7LC50hw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a9b52d-cf46-49dc-9acc-05bc0bccd96c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(180040, 5), dtype=float64, numpy=\n",
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Label encode labels"
      ],
      "metadata": {
        "id": "mJj5PH_q72h2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract labels (\"target\" columns) and encode them into integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"])\n",
        "val_labels_encoded = label_encoder.fit_transform(val_df[\"target\"])\n",
        "test_labels_encoded = label_encoder.fit_transform(test_df[\"target\"])\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_encoded"
      ],
      "metadata": {
        "id": "4xog0Kwc50e-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdbe0f72-8170-4a4c-eaf6-e85e8e69555c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names and number of classes from LabelEncoder instance\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "metadata": {
        "id": "7GqP7go950cZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5f450d0-7a6a-43c7-9c7a-d7af8d60a26f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Starting a series of modelling experiments...\n",
        "\n",
        "As usual, we're going to be trying out a bunch of different models ans seeing which one works best.\n",
        "\n",
        "And as always, we're going to start with a baseline (TF-IDF Multinomial Naive Bayes classifier)."
      ],
      "metadata": {
        "id": "Jnts8EsS77TR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model_0 : Getting a baseline"
      ],
      "metadata": {
        "id": "uDhOxVJC7_BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model_0 = Pipeline ([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "# fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels_encoded)"
      ],
      "metadata": {
        "id": "qBzxQ2ZM7870",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602b4bb0-892b-4483-e921-f029f46f54ab"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "baseline_score = model_0.score(val_sentences,val_labels_encoded)\n",
        "print(f\"our baseline model achive an accuracy of : {baseline_score}\")"
      ],
      "metadata": {
        "id": "OK98m7E_784l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a6db74-1aaf-4639-e2d1-b58fef6d7a5b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "our baseline model achive an accuracy of : 0.7516829593423684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction\n",
        "baseline_pred_probs = model_0.predict(val_sentences)\n",
        "baseline_preds = tf.squeeze(tf.round(baseline_pred_probs))\n",
        "baseline_preds[:10]"
      ],
      "metadata": {
        "id": "Q6l2nVJ2782n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68535109-a784-40a5-e788-1e339ed2406d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([1, 2, 4, 2, 2, 4, 4, 4, 4, 4])>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results = helper_functions.calculate_results(val_labels_encoded, baseline_preds)\n",
        "model_0_results"
      ],
      "metadata": {
        "id": "GQ7onaVg78zv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d5dc461-09e1-4e4f-bf1b-22dddd37680f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.16829593423684,\n",
              " 'precision': 0.7556121877731266,\n",
              " 'recall': 0.7516829593423684,\n",
              " 'f1': 0.734085177322999}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare our data (the text) for deep sequence models\n",
        "\n",
        "Before we start building deeper models, we've got to create vectorization and embedding layers"
      ],
      "metadata": {
        "id": "QZgpcmfU8Tmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# how long is each sentence on average ? \n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences] # list of length of words\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len\n",
        "#avg_sent_len, nb_word_per_sentence/len(train_sentences)"
      ],
      "metadata": {
        "id": "ZpESMVG58GWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d793b83f-a2e5-4959-82ac-22735b801ac5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(sent_lens, bins=20);"
      ],
      "metadata": {
        "id": "engVZkgb78x1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "1ec6493d-53cb-46a0-d37d-f41ee36d2760"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How long  of sentence lenght covers 95% of examples\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len "
      ],
      "metadata": {
        "id": "xpPsddx-78vL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c523b27-d8ce-4c3e-fbd6-a4d3b1c8c152"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximum sequence length in the training set\n",
        "max(sent_lens)"
      ],
      "metadata": {
        "id": "_Tb0yLQR78tN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1519a38b-4d46-4399-b1cb-0b2b51523997"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding and tokenization\n",
        "We want to make a layer which maps our texts from words to numbers"
      ],
      "metadata": {
        "id": "zxU1Ljj38Zlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many words are in our vocab? (taken from table 2 in : https://arxiv.org/pdf/1710.06071.pdf)\n",
        "max_tokens = 68000"
      ],
      "metadata": {
        "id": "xa8-xkcL78qm"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets create a text vectorizer use text vectorisation layers of the last video\n",
        "from helper_functions import tokenization, embedding\n",
        "# init the tokenizer function\n",
        "init_tokenizer = tokenization(train_sentences, output_seq_len, max_vocab_length=68000) \n",
        "\n",
        "# Choose a random sentence from the training dataset and tokenize it \n",
        "random_sentence = random.choice(train_sentences)\n",
        "text_vectorizer = init_tokenizer([random_sentence])\n"
      ],
      "metadata": {
        "id": "kwsTmbVB78oY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many words in our training vocabulary\n",
        "rct_20k_text_vocab = init_tokenizer.get_vocabulary()\n",
        "print(f\"Number of words i vocab:{len(rct_20k_text_vocab)}\\n\")\n",
        "print(f\"Most common words in the vocab:{rct_20k_text_vocab[:5]}\\n\")\n",
        "print(f\"least common words in the vocab:{rct_20k_text_vocab[-5:]}\\n\")"
      ],
      "metadata": {
        "id": "SDpW9Dqm78ld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1db671d-8664-4457-db6c-34b9fd59b126"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words i vocab:64841\n",
            "\n",
            "Most common words in the vocab:['', '[UNK]', 'the', 'and', 'of']\n",
            "\n",
            "least common words in the vocab:['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init_tokenizer.get_config()"
      ],
      "metadata": {
        "id": "nOT8lo7P50TO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f025edb-4a8c-49e8-cfa4-d291f493e2d3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'text_vectorization',\n",
              " 'trainable': True,\n",
              " 'dtype': 'string',\n",
              " 'batch_input_shape': (None,),\n",
              " 'max_tokens': 68000,\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'split': 'whitespace',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'sparse': False,\n",
              " 'ragged': False,\n",
              " 'vocabulary': None,\n",
              " 'idf_weights': None,\n",
              " 'encoding': 'utf-8'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create custom text embedding"
      ],
      "metadata": {
        "id": "FplDLmFq8goH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Init embedding \n",
        "init_embedding = embedding( output_seq_len,len(rct_20k_text_vocab), output_seq_len)\n",
        "text_embedding = init_embedding(text_vectorizer)\n",
        "text_embedding"
      ],
      "metadata": {
        "id": "GivMfkAF8cap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab3dc3e-3898-4734-dd3a-8ee7e3ca4323"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 55, 128), dtype=float32, numpy=\n",
              "array([[[ 0.02730227,  0.02818613,  0.0022382 , ...,  0.01214168,\n",
              "          0.0150726 ,  0.01370465],\n",
              "        [ 0.04398394,  0.04584178, -0.0010087 , ..., -0.00446225,\n",
              "         -0.00841194, -0.02034222],\n",
              "        [ 0.00098654, -0.04712598,  0.02432138, ..., -0.03179438,\n",
              "          0.00181348, -0.00988759],\n",
              "        ...,\n",
              "        [ 0.0261853 ,  0.02012846,  0.04628227, ..., -0.04740956,\n",
              "         -0.02748473, -0.02614648],\n",
              "        [ 0.0261853 ,  0.02012846,  0.04628227, ..., -0.04740956,\n",
              "         -0.02748473, -0.02614648],\n",
              "        [ 0.0261853 ,  0.02012846,  0.04628227, ..., -0.04740956,\n",
              "         -0.02748473, -0.02614648]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show example embedding\n",
        "print(f\"Sentence before vectorization:\\n {random_sentence}\\n\")\n",
        "print(f\"sentence after vectorization: \\n {text_vectorizer}\")\n",
        "print(f\"sentence after embedding: \\n {text_embedding}\")\n",
        "print(f\"embedding sentence shape:\\n {text_embedding.shape}\")"
      ],
      "metadata": {
        "id": "h3h_W-Zz8in-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4241fd-51cc-479b-d361-6e810976c655"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before vectorization:\n",
            " there were @ deaths in @ women randomised .\n",
            "\n",
            "sentence after vectorization: \n",
            " [[  61    9 1254    5   90  210    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
            "sentence after embedding: \n",
            " [[[ 0.02730227  0.02818613  0.0022382  ...  0.01214168  0.0150726\n",
            "    0.01370465]\n",
            "  [ 0.04398394  0.04584178 -0.0010087  ... -0.00446225 -0.00841194\n",
            "   -0.02034222]\n",
            "  [ 0.00098654 -0.04712598  0.02432138 ... -0.03179438  0.00181348\n",
            "   -0.00988759]\n",
            "  ...\n",
            "  [ 0.0261853   0.02012846  0.04628227 ... -0.04740956 -0.02748473\n",
            "   -0.02614648]\n",
            "  [ 0.0261853   0.02012846  0.04628227 ... -0.04740956 -0.02748473\n",
            "   -0.02614648]\n",
            "  [ 0.0261853   0.02012846  0.04628227 ... -0.04740956 -0.02748473\n",
            "   -0.02614648]]]\n",
            "embedding sentence shape:\n",
            " (1, 55, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating datasets (making sure our data loads as fast as possible)\n",
        "\n",
        "We're going to setup our data to run as fast a possible with the TensorFlow tf.data API, many of the steps here are discussed at length in these two resources:\n",
        "* https://www.tensorflow.org/guide/data_performance\n",
        "* https://www.tensorflow.org/guide/data"
      ],
      "metadata": {
        "id": "epAf7vAN8lnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our data into TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "anCWG1SK8ils",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44200fc9-a385-48b9-a90f-c21a2b91ffb4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_one_hot.shape, train_labels_one_hot[0]"
      ],
      "metadata": {
        "id": "lua2jEge8ii7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea314cae-512c-49cd-c387-4f49cb343407"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((180040, 5), array([0., 0., 0., 1., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the TensorSliceDataset's and turn them into prefechted data\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "nYBGl2468igl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a48e56a-164d-44ec-8b2f-b82180101bb9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "id": "wCEVpnzL8ieN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb79620e-9c49-4545-da6e-a3957489f5bf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5627"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1 : Conv1D with token embeddings"
      ],
      "metadata": {
        "id": "x2it5vo58p0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 1D conv model to process sequences\n",
        "num_classes"
      ],
      "metadata": {
        "id": "Wsjuq7bE8rVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23926870-9e8c-4f48-c2fd-f233b1b691a0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D, Dense, Input\n",
        "# create victorization, create embedding layer, create conv1D, pooling, dense layer\n",
        "model_1 = tf.keras.Sequential([\n",
        "    Input(shape=(1), dtype=tf.string, name='input_layer'),\n",
        "    init_tokenizer,\n",
        "    init_embedding,\n",
        "    Conv1D(64, kernel_size=5, padding='same', activation='relu'),\n",
        "    GlobalAveragePooling1D(), # Condense the output of our feature vector from conv layer\n",
        "    Dense(num_classes, activation='softmax')\n",
        "], name='Conv1D')\n",
        "\n",
        "# compile the model\n",
        "model_1.compile(loss= \"categorical_crossentropy\",\n",
        "               optimizer = tf.keras.optimizers.Adam(),\n",
        "               metrics = ['accuracy'])\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "kvIzS6yq8r6o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e09fab8c-8829-4354-c297-ac5aa51a7393"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 55)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " token_embedding (Embedding)  (None, 55, 128)          8299648   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 55, 64)            41024     \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 64)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,340,997\n",
            "Trainable params: 8,340,997\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "history_model_1 = model_1.fit(train_dataset,\n",
        "                              steps_per_epoch=int(0.1*len(train_dataset)), \n",
        "                              epochs=3,\n",
        "                              validation_data= valid_dataset,\n",
        "                              validation_steps=int(0.1*len(valid_dataset)),\n",
        "                              callbacks=[helper_functions.create_tensorboard_callback(dir_name=\"tensorboard\",\n",
        "                                                                                    experiment_name=\"model_1_conv1D\")])"
      ],
      "metadata": {
        "id": "j3Vte6_98r3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee663b4-2914-4817-c1bc-173535661ac2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: tensorboard/model_1_conv1D/20230213-201442\n",
            "Epoch 1/3\n",
            "562/562 [==============================] - 38s 51ms/step - loss: 0.9163 - accuracy: 0.6391 - val_loss: 0.5589 - val_accuracy: 0.7946\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 10s 18ms/step - loss: 0.6540 - accuracy: 0.7578 - val_loss: 0.5311 - val_accuracy: 0.8198\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 7s 13ms/step - loss: 0.6148 - accuracy: 0.7751 - val_loss: 0.5236 - val_accuracy: 0.8196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on whole validation dataset\n",
        "model_1.evaluate(valid_dataset)"
      ],
      "metadata": {
        "id": "a5HDIAHf8r1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24a9de5-cca7-42ab-fcb5-3a3181fbfb31"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5627/5627 [==============================] - 21s 4ms/step - loss: 0.5683 - accuracy: 0.8000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5683025121688843, 0.799988865852356]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions (our model predicts prediction probabilies for each class)\n",
        "model_1_pred_probs = model_1.predict(valid_dataset)\n",
        "model_1_pred_probs, model_1_pred_probs.shape # output = proba of ['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS']"
      ],
      "metadata": {
        "id": "peN6lSHm8ryz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "695eed9d-21c7-4399-86f7-96d6c6a28cec"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5627/5627 [==============================] - 24s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1.0525025e-01, 3.3547316e-02, 3.8075781e-05, 8.6116302e-01,\n",
              "         1.3546961e-06],\n",
              "        [6.8235320e-05, 3.7726888e-04, 9.6172744e-01, 4.8316877e-05,\n",
              "         3.7778810e-02],\n",
              "        [1.8673815e-02, 1.0212492e-01, 4.3821511e-01, 1.0454207e-02,\n",
              "         4.3053198e-01],\n",
              "        ...,\n",
              "        [3.2523733e-02, 3.0972785e-01, 4.5211826e-02, 1.7000126e-02,\n",
              "         5.9553647e-01],\n",
              "        [6.4356163e-02, 7.1616846e-01, 9.5809028e-03, 6.3496925e-02,\n",
              "         1.4639759e-01],\n",
              "        [4.8275536e-01, 5.7548616e-02, 1.5770450e-01, 2.9046938e-01,\n",
              "         1.1522152e-02]], dtype=float32), (180040, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pred_probs to classes\n",
        "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
        "model_1_preds"
      ],
      "metadata": {
        "id": "yy9DXstb8rwN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f363867-79a8-4dae-a41c-de542dfe2895"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(180040,), dtype=int64, numpy=array([3, 2, 2, ..., 4, 1, 0])>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                   y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "id": "fYJQfXqv8yL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22aa274a-0c52-4267-aaaa-c8276008c707"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.9988891357476,\n",
              " 'precision': 0.7972790640944883,\n",
              " 'recall': 0.7999888913574761,\n",
              " 'f1': 0.7976697547580185}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model_2 : TensorFlow Hub Pretrained Feature Extractor\n",
        "\n",
        "Now lets use pretrained word embedding from TensorFlow Hub, more specifically the universal sentence encoder(universal-sentence-encoder): https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "\n",
        "The paper originally used GloVee embeddings, however, we're going to stick with the later created USE pretrained embedding"
      ],
      "metadata": {
        "id": "fDchPqK1MOCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pretrained TensorFlow Hub USE\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                  trainable=False,\n",
        "                                  name=\"universal_sentence_encoder\")\n",
        "embeddings = tf_hub_embedding_layer([\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"I am a sentence for which I would like to get its embedding\"])\n",
        "\n",
        "print(embeddings)"
      ],
      "metadata": {
        "id": "sLSvGUEMqRre",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef57866e-a78e-4a9b-a9ec-d8219ef680e2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[-0.03133019 -0.06338634 -0.016075   ... -0.0324278  -0.04575739\n",
            "   0.05370454]\n",
            " [ 0.0508086  -0.01652432  0.01573776 ...  0.00976659  0.0317012\n",
            "   0.01788117]], shape=(2, 512), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out the pretrained embedding on a random sentence\n",
        "random_train_sentence = random.choice(train_sentences)\n",
        "print(f\"Random sentence:\\n {random_train_sentence}\")\n",
        "use_embedded_sentence = tf_hub_embedding_layer([random_train_sentence])\n",
        "print(f\"sentence after embedding:\\n{use_embedded_sentence[0][:30]}\")\n",
        "print(f\"Length of sentence embedding: {len(use_embedded_sentence[0])}\")"
      ],
      "metadata": {
        "id": "SmxuXp5HqRnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d7f1c8-cd65-4cd3-d4d7-b86f8fc4648c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random sentence:\n",
            " the primary goal of fluid therapy is to maintain fluid homeostasis .\n",
            "sentence after embedding:\n",
            "[ 0.06041823 -0.02541832 -0.02646389 -0.00824145  0.05800492 -0.04481555\n",
            " -0.03313271  0.03544587  0.07334206  0.02849195  0.07769401  0.02603306\n",
            " -0.03392129 -0.03456586 -0.05362946 -0.06122088 -0.0816453   0.01198747\n",
            " -0.01343635  0.00533054 -0.08030574 -0.00799438  0.07701387 -0.03791163\n",
            "  0.00599307 -0.04013539  0.00408186  0.02542625  0.03351009  0.00128141]\n",
            "Length of sentence embedding: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building and fitting an NLP feature extraction model using pretrained embeddings from TensorFlow Hub "
      ],
      "metadata": {
        "id": "ZMXhVASB-BbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = tf.keras.Sequential([\n",
        "    tf_hub_embedding_layer,\n",
        "    tf.keras.layers.Dense(5, activation='sigmoid')\n",
        "])\n",
        "# compile the model\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "yQ7G0kSrqRkf"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "model_2.fit(train_dataset,\n",
        "            steps_per_epoch=int(0.1*len(train_dataset)),\n",
        "            epochs=3,\n",
        "            validation_data=valid_dataset,\n",
        "            validation_steps=int(0.1*len(valid_dataset)),\n",
        "            callbacks=[helper_functions.create_tensorboard_callback(dir_name=\"tensorboard\",\n",
        "                                                                    experiment_name=\"model_2_tf_hub_embed\")])"
      ],
      "metadata": {
        "id": "I0jTYs7CqRf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960b0c09-331e-4b25-bf3e-1a2bcfd0a3da"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: tensorboard/model_2_tf_hub_embed/20230213-201744\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "562/562 [==============================] - 18s 24ms/step - loss: 1.2622 - accuracy: 0.5415 - val_loss: 1.0893 - val_accuracy: 0.6018\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 17s 30ms/step - loss: 1.0126 - accuracy: 0.6259 - val_loss: 0.9608 - val_accuracy: 0.6507\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 17s 30ms/step - loss: 0.9321 - accuracy: 0.6561 - val_loss: 0.9009 - val_accuracy: 0.6718\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcf530ad0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Ayf96EM83An"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=[], dtype=\"string\"),\n",
        "    tf_hub_embedding_layer, # tokenize text and create embedding of each sequence (512 long vector)\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    # Note : you could add more layers here if you wanted to\n",
        "    tf.keras.layers.Dense(num_classes, activation='sigmoid', name=\"output_layer\")\n",
        "], name=\"model_2_tf_hub_embed\")\n",
        "\n",
        "# compile the model\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "qnseJl3agjXA"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "history_model_2 = model_2.fit(train_dataset,\n",
        "                              steps_per_epoch=int(0.1*len(train_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=valid_dataset,\n",
        "                              validation_steps=int(0.1*len(valid_dataset)),\n",
        "                              callbacks=[helper_functions.create_tensorboard_callback(dir_name=\"tensorboard\",\n",
        "                                                                    experiment_name=\"model_2_tf_hub_embed\")])"
      ],
      "metadata": {
        "id": "oJ2NWIXG8xSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc627d6-b51a-44c8-c03c-a8f192da9ef8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: tensorboard/model_2_tf_hub_embed/20230213-201910\n",
            "Epoch 1/3\n",
            "562/562 [==============================] - 15s 24ms/step - loss: 0.9164 - accuracy: 0.6488 - val_loss: 0.7803 - val_accuracy: 0.7048\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 18s 32ms/step - loss: 0.7691 - accuracy: 0.7017 - val_loss: 0.7535 - val_accuracy: 0.7149\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 13s 23ms/step - loss: 0.7532 - accuracy: 0.7127 - val_loss: 0.7425 - val_accuracy: 0.7142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the whole validation dataset\n",
        "model_2.evaluate(valid_dataset)"
      ],
      "metadata": {
        "id": "wu6lMdX78zHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcdfa624-6519-436c-e494-5695ca187a1d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5627/5627 [==============================] - 66s 12ms/step - loss: 0.7453 - accuracy: 0.7120\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7452996373176575, 0.7120473384857178]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make some prediction wit feature extraction model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)"
      ],
      "metadata": {
        "id": "V9Lwnovi_7dp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cfec637-93ec-49f9-c1b4-f17d53f24fbe"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5627/5627 [==============================] - 67s 12ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the prediction probabilities found with feature extraction model to label\n",
        "model_2_pred = tf.argmax(model_2_pred_probs, axis=1) # les positions des  valeur les plus grandes \n",
        "model_2_pred"
      ],
      "metadata": {
        "id": "y2rfb07TAJT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1d72b6-6385-4d33-fc1e-9e6550c03afd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(180040,), dtype=int64, numpy=array([3, 2, 2, ..., 1, 1, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcute results performance from TF Hub pretrained embeddings results on val set\n",
        "model_2_results = calculate_results(y_true =val_labels_encoded,\n",
        "                                    y_pred = model_2_pred)\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "89t0WYm9A-oZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "420c6c61-07a0-4fa5-a818-30d1cf6b7301"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 71.20473228171518,\n",
              " 'precision': 0.7149666847255184,\n",
              " 'recall': 0.7120473228171518,\n",
              " 'f1': 0.7095351663978483}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results"
      ],
      "metadata": {
        "id": "hZTM-62TBSgw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b944e33c-98da-4638-e620-ee431b965201"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.16829593423684,\n",
              " 'precision': 0.7556121877731266,\n",
              " 'recall': 0.7516829593423684,\n",
              " 'f1': 0.734085177322999}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results"
      ],
      "metadata": {
        "id": "_nkk7jHhC7Bp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a79dd79-54d8-4b75-e657-0883de16fd0c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.9988891357476,\n",
              " 'precision': 0.7972790640944883,\n",
              " 'recall': 0.7999888913574761,\n",
              " 'f1': 0.7976697547580185}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3: Conv1D with character embeddngs\n",
        "\n",
        "The paper which we're replicating states they used a combination of token and character-level embeddings.\n",
        ":\n",
        "Previously we've token-level embeddings but we'll need to do similar steps for characters if we want to use char-level embeddings."
      ],
      "metadata": {
        "id": "SWWTHTgyDtqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a characterlevel tokenizer"
      ],
      "metadata": {
        "id": "5EYXAotxiQcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tr = train_sentences.split(\"\")\n",
        "#init_tokenizer\n",
        "type(train_sentences)"
      ],
      "metadata": {
        "id": "P_UUJRurC9qY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ecf270f-abfb-44fe-a14f-dff96405a4b2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DKdX1_g8ihyS"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_chars(text):\n",
        "  return \" \".join(list(text))\n",
        "\n",
        "# Text splitting non-character-level sequence into characters\n",
        "split_chars(random_train_sentence)"
      ],
      "metadata": {
        "id": "6g4xJJb4i9o5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1efec99d-3c53-41c4-cfb1-67edb8274ffb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'t h e   p r i m a r y   g o a l   o f   f l u i d   t h e r a p y   i s   t o   m a i n t a i n   f l u i d   h o m e o s t a s i s   .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split sequence-level data splits into character-level data splits \n",
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
        "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "train_chars[0]"
      ],
      "metadata": {
        "id": "bLO6YMzslFfJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f831c6cd-0448-43fd-b6aa-d8cbea6f1754"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What's the average character length ?\n",
        "char_lens = [len(sentence) for sentence in train_sentences]\n",
        "mean_char_len = np.mean(char_lens)\n",
        "mean_char_len"
      ],
      "metadata": {
        "id": "iaPp-0PhlVEQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edecd4b0-60c6-40b7-ac17-d4fefb20cb46"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149.3662574983337"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distribution of our sequences at a character-level\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(char_lens, bins=7);"
      ],
      "metadata": {
        "id": "GOtCO6CKplHR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e832d9d5-5529-4271-d35e-7dd4f5a87ae7"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find what character length covers 95% of sequences\n",
        "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
        "output_seq_char_len"
      ],
      "metadata": {
        "id": "zyriVeG8q4_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "868331f1-a3ba-4856-b1c6-430f3f496e75"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all keyboard characters\n",
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet"
      ],
      "metadata": {
        "id": "q7mvXmEQrk_6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6763b79c-85dc-4fd0-df58-d111ffbdac7e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char-level token vectorizer instance\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2 # add 2 for space and OOV token (OOV = out of vocab, '[UNK]')\n",
        "\n",
        "\n",
        "    # Create a text vectorizer \n",
        "char_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens = NUM_CHAR_TOKENS,\n",
        "                                                                               output_sequence_length= output_seq_char_len,\n",
        "                                                                               #standardize=None, # set standardization to \"None\" if you want leave the ponctuation in\n",
        "                                                                               name=\"char_vectorizer\")\n"
      ],
      "metadata": {
        "id": "MZDBAEhfsHkK"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapt character vectorizer to training character\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "metadata": {
        "id": "5V9LCMyCsJ_L"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Check character vocab stats\n",
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "print(f\"Number of different characters in character vocab: {len(char_vocab)}\")\n",
        "print(f\"5 most common characters: {char_vocab[:5]}\")\n",
        "print(f\"5 least common characters: {char_vocab[-5:]}\")"
      ],
      "metadata": {
        "id": "1503Ul8YFBJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc63d187-9fc6-45e5-f9ad-fddec17fbca6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of different characters in character vocab: 28\n",
            "5 most common characters: ['', '[UNK]', 'e', 't', 'i']\n",
            "5 least common characters: ['k', 'x', 'z', 'q', 'j']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out character vectorizer\n",
        "random_train_chars = random.choice(train_chars)\n",
        "print(f\"Charified text:\\n {random_train_chars}\")\n",
        "print(f\"Length of random_train_chars: {len(random_train_chars)}\")\n",
        "\n",
        "vectorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f\"\\Vectorized chars:\\n {vectorized_chars}\")\n",
        "print(f\"\\nLength of vectorized chars: {len(vectorized_chars[0])}\")"
      ],
      "metadata": {
        "id": "8hI75G6sC_jR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc496049-57ae-4748-b858-cbccb5d0a8c1"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text:\n",
            " a d d i t i o n a l l y   ,   w e   a i m   t o   a s s e s s   t h e   s a f e t y   o f   i a t   ,   a n d   t h e   e f f e c t   o n   r e c a n a l i z a t i o n   o f   d i f f e r e n t   m e c h a n i c a l   t r e a t m e n t   m o d a l i t i e s   .\n",
            "Length of random_train_chars: 261\n",
            "\\Vectorized chars:\n",
            " [[ 5 10 10  4  3  4  7  6  5 12 12 19 20  2  5  4 15  3  7  5  9  9  2  9\n",
            "   9  3 13  2  9  5 17  2  3 19  7 17  4  5  3  5  6 10  3 13  2  2 17 17\n",
            "   2 11  3  7  6  8  2 11  5  6  5 12  4 25  5  3  4  7  6  7 17 10  4 17\n",
            "  17  2  8  2  6  3 15  2 11 13  5  6  4 11  5 12  3  8  2  5  3 15  2  6\n",
            "   3 15  7 10  5 12  4  3  4  2  9  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0]]\n",
            "\n",
            "Length of vectorized chars: 290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a character level embedding"
      ],
      "metadata": {
        "id": "fpAI-4BpdsRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char embedding layer\n",
        "char_embed = tf.keras.layers.Embedding(input_dim=len(char_vocab), # this is the number of differente characters\n",
        "                                       output_dim= 25, # is the size of char_embedding in  the paper (figure 1)\n",
        "                                       mask_zero=True,\n",
        "                                       name=\"char_embed\")"
      ],
      "metadata": {
        "id": "_iy5snMeKhWw"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our character embedding layer\n",
        "print(f\"Charified text:\\n {random_train_chars}\")\n",
        "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
        "print(f\" Embedded chars. (after vectorization and embedding) :\\n {char_embed_example}\")\n",
        "print(f\"Character embedding shape: {char_embed_example.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCTKoO9SiL2O",
        "outputId": "a39c2b90-54b3-495a-b76a-b1fc78043a8e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text:\n",
            " a d d i t i o n a l l y   ,   w e   a i m   t o   a s s e s s   t h e   s a f e t y   o f   i a t   ,   a n d   t h e   e f f e c t   o n   r e c a n a l i z a t i o n   o f   d i f f e r e n t   m e c h a n i c a l   t r e a t m e n t   m o d a l i t i e s   .\n",
            " Embedded chars. (after vectorization and embedding) :\n",
            " [[[-0.01206168  0.00573943  0.03848543 ... -0.0190544   0.02634421\n",
            "    0.00118039]\n",
            "  [ 0.00063689  0.0425622  -0.03162541 ... -0.04974445  0.04153029\n",
            "    0.02015552]\n",
            "  [ 0.00063689  0.0425622  -0.03162541 ... -0.04974445  0.04153029\n",
            "    0.02015552]\n",
            "  ...\n",
            "  [ 0.01541502 -0.02595352  0.02098617 ...  0.00329386 -0.03929961\n",
            "    0.04308702]\n",
            "  [ 0.01541502 -0.02595352  0.02098617 ...  0.00329386 -0.03929961\n",
            "    0.04308702]\n",
            "  [ 0.01541502 -0.02595352  0.02098617 ...  0.00329386 -0.03929961\n",
            "    0.04308702]]]\n",
            "Character embedding shape: (1, 290, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(random_train_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCFdmLcxjIc3",
        "outputId": "9dd9f2eb-a16b-4a6a-89f0-dff8dacbba29"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "261"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the image in notion and build a model like this"
      ],
      "metadata": {
        "id": "SeLxgph3ja6G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}